---
title: Mais qui a des téléphones ?!
author: Justine Blanchot et Elyass Sayd, Groupe 0
date: 25/04/2022
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    theme: united
  pdf_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment = NA, echo = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.align = "center", out.width = "80%")
```

```{css layout, echo = FALSE}
h1, title, .author, .date {
  text-align: center;
}
p {
	text-indent: 20px;
}
```

<br>

## Introduction

Avant la fameuse conférence *Apple Keynote* de 2007 par Steve Jobs où il annonçait la sortie du premier iPhone, personne n'aurait pu imaginer que les écrans tactiles se retrouveraient dans toutes les mains. L'iPhone était le précurseur du marché des smartphones, marché qui a connu une des expansions les plus fulgurantes du XXe siècle, avec l'amélioration constante des infrastructures internet. Aurions-nous pu prévoir quels marchés allaient-être les plus réceptifs à l'arrivée de cette technologie? À l'aide de quels critères? Nous allons au fil de ce rapport nous questionner sur les corrélations possibles pour un pays donné entre le nombre de téléphones pour mille habitants et différents critères classiques pour mesurer le développement d'un pays.

<br>

## Problématique et objectif

A partir d'un jeu de données issu de Kaggle, publié en 2017 par Fernando Lasso, intitulé "Countries of the world" et rassemblant des données du gouvernement américain (anciennes données du CIA World Factbook et International Consortium for the Advancement of Academic Publication <https://gsociology.icaap.org/dataupload.html>), nous allons essayer d'expliquer l'engouement autour du téléphone mobile en 2000 en fonction de certains indicateurs.
Nous tenterons donc de répondre à la problématique suivante:

**Aurions-nous pu anticiper la réussite du marché des téléphones portables dans un pays à l'aide des indicateurs classiques de développement? Si oui, à l'aide desquels?**

Si le temps nous le permet, nous comparerons notre analyse avec des nouvelles données plus récentes du World Factbook.

***

## I - Analyse descriptive des données

### A - Analyse du jeu de données

Le jeu de données que nous avons choisi contient les données de 227 pays par rapport à 19 variables. Dans le cadre de cette étude, nous nous limiterons aux variables suivantes: la région d'appartenance du pays, la densité de population (nombre d'habitants par miles carré), le PIB par habitant, le taux de natalité et, enfin, la part de la population active travaillant dans l'agriculture, l'industrie et les services.

```{r installation packages, eval = FALSE}
install.packages("ggplot2")
install.packages("ggThemeAssist")
install.packages("gridExtra")
install.packages("GGally")
install.packages("carData")
install.packages("car")
install.packages("leaps")
```

```{r import-nettoyage-données}
library("ggplot2")
library("ggThemeAssist")
library("gridExtra")
library("GGally")
library("car")
library("carData")
library("leaps")
df.original <- read.csv("countries.csv", dec=",", encoding="UTF-8")
df.countries <- df.original[, c("Pays", "Téléphones", "Région", "Densité.population", "PIB", "Agriculture", "Industrie", "Services", "Taux.de.natalité")]
rownames(df.countries) <- df.countries$Pays
vec_retirer = is.na(df.countries)
idx = apply(vec_retirer, 1, sum) == 0
df.countries <- df.countries[idx, ]
```

Pour être en adéquation avec les consignes du projet, nous avons choisi 7 variables d'intérêt, puisqu'il était recommandé d'en prendre 3 ou 4 minimum. Nous avons vérifié que nous avions une variable qualitative: la région d'appartenance des pays. Toutes les autres variables sont quantitatives. Les noms des colonnes du fichier ont été renommées en français. Notre variable d'intérêt possèdait 4 valeurs manquantes. C'est également le cas pour certaines de nos variables explicatives. Nous avons décidé de retirer les pays où il manque des données de notre étude. Il reste donc `r dim(df.countries)[1]` pays. Il était demandé d'avoir au minimum 100 données, ce qui est donc le cas dans notre "nouveau" jeu de données.

<br>

### B - Analyse univariée de la variable d'intérêt

Introduisons des notations: $T$, pour téléphones, est la variables à expliquer, c'est-à-dire le nombres de téléphones pour mille habitants.  
$T$ est la réalisation d'une variable aléatoire $X$.  

Dans cette première partie, nous allons analyser les données de $T$ et essayer de déterminer la loi de $X$.  
Commençons par regarder quelques caractéristiques de $T$:

```{r résumé-sommaire}
sommaire <- summary(df.countries$Téléphones)
mu = sommaire["Mean"]
sommaire
boxplot_téléphones <- ggplot(data=df.countries) + aes(y=Téléphones) + geom_boxplot() + labs(title = "Box-plot de la variable Téléphones") + theme(plot.title = element_text(hjust = 0.5))
boxplot_téléphones
```

On peut commencer à analyser les indicateurs statistiques de notre échantillon. Par lecture de notre sommaire et de notre box-plot, on obtient que la loi n'est pas symétrique, puisque la moyenne, `r mu` est différente de la médiane,`r sommaire["Median"]`.

Les deux indicateurs de tendance centrales sont assez bas. Le premier quartile est à `r sommaire["1st Qu."]` mais surtout le troisième quartile est égal à `r sommaire["3rd Qu."]`. Cela signifie que 75% des pays ont moins de `r sommaire["3rd Qu."]` téléphones pour mille habitants.  
L'étendue est de `r sommaire["Max."] - sommaire["Min."]`, mais cet indicateur est sensible aux valeurs aberrantes et nous voyons dans notre box-plot que nous en avons une. De plus, la longueur d'une des moustaches est assez élevée. L'écart-interquartile, plus robuste que l'étendue, est de `r sommaire["3rd Qu."] - sommaire["1st Qu."]`. Ainsi, la moitié des pays ont entre `r sommaire["1st Qu."]` et `r sommaire["3rd Qu."]` téléphones pour mille habitants.

```{r maximum}
indice_max <- which.max(df.countries$Téléphones)
ligne_max <- df.countries[indice_max,]
```

L'observation hors-norme est due aux `r ligne_max$Pays` soit les États-Unis. Ce n'est pas suprenant que ce soit le pays qui ait le plus de téléphones pour mille habitants, au vu de leurs intérêts et rôle dans la technologie et l'essor des téléphones portables. Nous voyons sur le box-plot qu'elle n'est pas tant éloigné de la fin de la moustache. Pour l'instant nous gardons cette donnée, nous verrons plus tard si elle est à supprimer.

<br>

Avant toutes recherches plus précises sur notre variable $T$, nous allons nous convaincre qu'elle est continue. Pour ce faire, traçons sa fonction de répartition empirique.

```{r fdrplot, out.width = "70%"}
fdrplot <- ggplot(df.countries, aes(Téléphones)) + stat_ecdf(geom="step") + labs(title="Fonction de répartition empirique de T" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))
long <- length(unique(df.countries$Téléphones))
fdrplot
```

<br>

On voit que la fonction de répartition empirique de $T$ réalise beaucoup de sauts. Elle en réalise exactement `r long` ce qui est suffisamment "grand" devant `r dim(df.countries)[1]` donc notre variable d'intérêt est continue.

Traçons son histogramme. Nous allons en tracer deux avec un nombre d'intervalles différents pour avoir une vision plus précise.

```{r histogrammes-T, out.width = "100%"}
hist1 <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 20)
hist1 <- hist1 + labs(title="Histogramme de T", subtitle = "2O sous-intervalles de [0,1000]") + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))

hist2 <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 10)
hist2 <- hist2 + labs(title="Histogramme de T", subtitles=" 10 sous-intervalles de [0,1000]" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))

grid.arrange(hist1, hist2)
```

<br>

Les histogrammes sont uni-modaux avec un pic en 0, puis à tendance décroissante. On en déduit que dans notre jeu de données, beaucoup de pays ont moins de 100 téléphones pour mille habitants et à l'inverse, peu de pays ont plus de de 700 téléphones pour mille habitants.

Au vu de ces histogrammes, nous pouvons penser que $T$ est un échantillon de loi exponentielle, c'est-à-dire $X$ suit une loi exponentielle de paramètre $\lambda$. L'espérance d'une loi exponentielle est $\frac{1}{\lambda}$. La méthode des moments nous propose la moyenne empirique de $T$ comme estimateur sans biais, consistant et asymptotiquement normal de l'espérance.

Dans le sommaire plus haut, nous avons vu que la moyenne empirique de $T$ est $\mu =$ `r mu`. En prenant $\hat \lambda =$ `r 1/mu`, nous voulons vérifier que notre hypothèse est acceptable, c'est-à-dire que la variable Téléphones suit une loi exponentielle de paramètre $\hat \lambda =$ `r 1/mu`. Nous allons alors tracer:

1.  L'histogramme de $T$ et la densité $\hat \lambda e^{-\hat \lambda x}$

2.  La fonction de répartition empirique de $T$ et la fonction de répartition de $X \sim \mathcal{E} (\hat \lambda )$.

3.  Le QQ-plot entre les quantiles théoriques de $X$ et les quantiles empiriques de $T$.

```{r T-exponentielle, fig.height = 6, fig.width = 8, out.width = "100%"}
lambda = 1/mu
hist <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 8, aes(y = stat(density)))
hist <- hist + labs(title="Comparaison histogramme-densité" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("")
hist <- hist + stat_function(fun = function(x) {dexp(x, rate = lambda)}, col = 'blue') + theme(plot.title = element_text(hjust = 0.5))

fdrplot <- ggplot(df.countries, aes(Téléphones)) + stat_ecdf(geom="step") + labs(title="Comparaison fonctions de répartition" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("")
fdrplot <- fdrplot + stat_function(fun = function(x) {pexp(x, rate = lambda)}, col = 'blue') + theme(plot.title = element_text(hjust = 0.5))

cdfexp <- function(x, rate) {
  return(1 - exp(rate*x))
}

df.qq <- data.frame(df.countries$Téléphones)
names(df.qq) <- "Téléphones"
df.qq$Téléphones <- df.qq$Téléphones/mu
qqplot <- ggplot(data = df.qq, aes(sample = Téléphones)) + stat_qq(distribution = stats::qexp)
qqplot <- qqplot + geom_abline(intercept = 0,slope = 1, col = "blue") + labs(title="Diagramme quantile-quantile") + xlab("Quantiles théoriques") + ylab("Quantiles obeservés") + theme(plot.title = element_text(hjust = 0.5))

grid.arrange(hist, fdrplot, qqplot, layout_matrix = rbind(c(1,3),c(2,3)), widths = c(1/2, 1/2))
```

<br>

Tout d'abord, les points de notre QQ-plot s'alignent bien sur la première bissectrice. C'est encourageant. De même, la courbe de densité de notre loi théorique approche notre histogramme. Il en est de même pour notre fonction de répartition. L'adéquation n'est pas parfaite mais elle est suffisamment raisonnable pour retenir l'hypothèse que $T$ suit une loi exponentielle de paramètre $\hat \lambda$.

Nous allons finaliser notre analyse univariée en réalisant un test de Kolmogorov-Smirnov sur notre échantillon, puisque la variable Téléphones et la loi exponentielle sont toutes deux des lois continues.

```{r test-T}
rexpsample <- df.countries$Téléphones/mu
kstest <- ks.test(df.countries$Téléphones, rexpsample)
kstest
p <- kstest$p.value
```

<br>

Notre p-valeur est inférieure à 2.2e-16 donc on rejette $H_0$ au profit de l'hypothèse alternative $H_1$ sans hésitation. On peut conclure que notre variable $T$ ne suit pas une loi exponentielle de paramètre $\hat\lambda$. $T$ est la réalisation d'une autre loi, dont on ne connait pas la nature exacte.

Nous avons ainsi terminé cette partie d'analyse univariée. Si besoin, nous réaliserons d'autre tests d'adéquation à des lois connues pour obtenir la loi de $T$.

<br>

### C - Analyse bi-variée

Nous allons maintenant nous intéresser aux potentielles corrélations entre notre variable d'intérêt $T$ et les autres variables de notre jeu de données.

Commençons par calculer la matrice de corrélation et présentons un diagramme de dispersion de toutes les paires de variables, pour chaque variable quantitative de notre jeu de données.

```{r corrélations-df, results = 'hide', out.width = "100%"}

df.countries.sans.pays <- df.countries[, -c(1)]
df.countries.sans.pays.region <- df.countries.sans.pays[, -c(2)]
df.countries.sans.pays.region <- scale(df.countries.sans.pays.region)
df.countries.sans.pays.region <- as.data.frame(df.countries.sans.pays.region)
ggpairs1 <- ggpairs(df.countries.sans.pays.region[, c(1:3,7)])
ggpairs2 <- ggpairs(df.countries.sans.pays.region[, c(1,4:6)])

cor(df.countries.sans.pays.region)
ggpairs1
ggpairs2
```

On a un facteur de corrélation d'environ 0.85 pour le couple de variables $T$ et PIB; on en déduit qu'elles sont fortement corrélées linéairement. Il en est de même pour les variables Services et $T$ avec un facteur de corrélation de 0.68. Finalement, la variable $T$ est également corrélée négativement à la variable Agriculture avec un coefficient de corrélation de -0,62 et à la variable Taux de natalité avec un coefficient de -0,73.

Analysons maintenant les nuages du points des paires de variables:

-   ($T$, Densité de population): la tendance semble montrer une corrélation, mais c'est peut être l'effet de certaines observations très grandes, qui ont écrasé un nuage de points qui aurait semblé aléatoire. Le coefficient est en lui même faible.

-   ($T$, PIB): les points sont relativement alignés sur une droite, ce qui est cohérent avec le coefficient de corrélation.

-   ($T$, Taux de natalité): les points ont l'air concentré dans une région du plan sous une hyperbole et dans le premier quart du plan. Le modèle idéal n'est peut être pas linéaire pour cette variable.

-   ($T$, Agriculture): même remarque que pour le taux de natalité.

-   ($T$, Industrie): le nuage de points semble un peu plus éparpillé, mais le coefficient de corrélation est nettement plus faible que pour les autres variables.

-   ($T$, Services): ici la tendance est marquée sur le nuage, avec le plus grand des coefficients de corrélation.

<br>

Nous avons maintenant une idée plus claire des liens entre notre variables d'intérêt et les variables quantitatives de notre jeu de données.

Nous allons terminer cette partie en nous intéressant à la variables Région, qui est une variable qualitative. Traçons le boxplot de la variable $T$ pour chaque modalité de la variable Région.

```{r boxplot-régions, out.width = "100%"}
boxplot_region <- ggplot(data=df.countries) + aes(x=as.factor(Région), y=Téléphones) + scale_x_discrete(guide = guide_axis(n.dodge=4)) + geom_boxplot() +xlab("Régions")
boxplot_region
```

Les boxplots sont très différents, on peut penser que la région d'appartenance du pays joue un rôle important sur le nombre de téléphones pour mille habitants. On remarque qu'en Amérique du nord et en Europe de l'ouest, les médianes sont hautes alors qu'elles sont beaucoup plus basses en Afrique Sub-saharienne, en Océanie ou encore en Asie. Il y a parfois des observations hors-normes, notamment en Afrique sub-saharienne. Nous reviendrons, ci-besoin, sur ces observations plus loin dans le rapport.

<br>

## II - Régression linéaire multiple

### A - Introduction

Dans cette partie, nous allons nous intéresser à une régression linéaire permettant d'exprimer le nombre de téléphones pour mille habitants par la densité de population (nombre d'habitants par miles carré), le PIB par habitant, le taux de natalité et enfin la part de la population active travaillant dans l'agriculture, l'industrie et les services.

On considère le modèle linéaire suivant:

<h4 style="text-align: center;">
Téléphones = $\beta_0$ + $\beta_1$PIB + $\beta_2$Densité + $\beta_3$ Agriculture + $\beta_4$Industrie + $\beta_5$Services + $\beta_6$Taux de natalité + $\varepsilon$
</h4>

Réalisons une première régression linéaire.

```{r sommaire-régression, out.width = "100%"}

mod1 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Industrie + Services + Taux.de.natalité, data = df.countries)
summary_mod1 <- summary(mod1)
summary_mod1
```

Annalysons ce sommaire. Le $R^2$ vaut `r summary_mod1$r.squared` qui est proche de 1 avec une p-valeur associée très faible,donc on rejette l'hypothèse selon laquelle tous les $\beta_j$ sont nuls pour $j=0,...,6$. Le modèle de régression linéaire permet d'expliquer relativement bien notre variable $T$.

De plus, les tests de significativité des coefficients $\beta_1$ et $\beta_6$ donnent des p-valeurs inférieures à 0.001, donc $\beta_1$ et $\beta_6$ sont non nuls.

Passons à l'étape de validation du modèle pour nous assurer que le modèle que nous avons choisi reflète la réalité.

<br>

### B - Analyse des résidus

Commençons par regarder si nous avons des valeurs aberrantes.

```{r résidus-student, out.width = "70%"}
df.residus <- data.frame(residu = rstudent(mod1))
n <- length(df.countries$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupes <- rep("Valeur non aberrante", n)
df.residus[ID_suspect, ]$Groupes <- "Valeur aberrante"

plot_rstudent <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupes) + geom_point()
plot_rstudent <- plot_rstudent + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_text(aes(label=ID), hjust = 0, vjust = 0)
plot_rstudent <- plot_rstudent + xlab('Index') + ylab('Résidus studentisés')
plot_rstudent

nb_aberrant1 <- sum(abs(df.residus$residu) > 2)
```

On a `r nb_aberrant1` valeurs aberrantes dans un échantillon de taille `r dim(df.countries)[1]` donc 95% des résidus studientisés $t_i^*$ se trouvent dans l'intervalle [−2,2]. On voit que certains résidus studentisés sont éloignés de l'intervalle [−2,2] comme l'observation 79 qui est le `r df.countries$Pays[79]` une île anglo-normande, l'observation 115 qui est le `r df.countries$Pays[115]` ou encore l'observation 160 qui est `r df.countries$Pays[160]`, une île caribéenne. Nous gardons pour l'instant tous les pays.

<br>

Nous allons nous intéresser à l'existence de point levier afin d'identifier si certaines observations sont trop influentes.

```{r points-leviers}
# Points leviers
p <- mod1$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod1))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupes <- rep("Point non levier", n)
df.H[ID_levier, ]$Groupes <- "Point levier"

plot_levier <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupes) + geom_point()
plot_levier <- plot_levier + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier <- plot_levier + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier <- plot_levier + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier <- plot_levier + xlab('Index') + ylab('hii')
plot_levier

nb_aberrant2 <- sum(df.H$H > seuil2)
```

Il y a `r nb_aberrant2` points leviers qui dépassent le deuxième seuil. Parmi les points leviers, l'observation 19 qui est le Bélize et l'observation 115 qui est le Luxembourg sont également des observation abérrantes. Nous décidons de retirer ces pays de notre échantillon, et de réaliser à nouveau une régression linéaire sans ces observations.

```{r nouveau-dataframe}
nouvcountries <- df.countries[c(-19,-115), ]
mod2 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Industrie + Services + Taux.de.natalité, data = nouvcountries)
summary(mod2)
```

Le nouveau jeu de données permet de garder à nouveau $\beta_1$ et $\beta_6$ qui ont des p-valeurs associées inférieures à 0.001. Désormais $\beta_0$ , $\beta_3$, $\beta_4$ et $\beta_5$ ont des p-valeurs associées inférieures à 0,01. Toutes nos variables semblent donc corrélées linéairement à $T$ à l'exception de la densité de population.

<br>

À présent, nous allons réaliser une analyse de la normalité des résidus. Traçons un QQ-plot qui compare les quantiles empiriques associés aux studendisés ( $t_1^*,...,t_n^*$) aux quantiles de la loi de Student $\mathcal{T}(n-p-1)$ pour valider l'hypothèse que les résidus sont suivent une loi normale.

```{r qqplot-residus}
# QQ-plot residus et studentisés

n <- length(nouvcountries$Téléphones)
p <- mod2$rank
df.residus2 <- data.frame(residu = rstudent(mod2))

quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs = sort(df.residus2$residu), Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)")
qq.plot
```

<br>

Les quantiles empiriques associés aux studendisés ($t_1^*,...,t_n^*$) aux quantiles de la loi de Student $\mathcal{T}(n-p-1)$ sont alignés. Nous pouvons donc valider l'hypothèse de la normalité des résidus.

Finissons cette analyse en mesurant l'influence de l'observation $i$ sur l'estimation des paramètre $\beta_j$ à l'aide des distances de Cook.

```{r distances-cook}
# Distance de cook
df.cook <- data.frame(cook = cooks.distance(mod2))
s1 <- qf(0.5, p, n-p)
s2 <- qf(0.1, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 2)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 3)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook')
plot_cook
```

Seulement 2 observations dépassent le premier seuil et aucune ne dépasse le second. Cela a du sens puisque nous avons déjà retiré les observations trop influentes et aberrantes en même temps. Nous décidons alors de conserver le reste de nos observations.

<br>

### C - Sélection de variables

Maintenant que nos données sont de "bonne qualité", procédons à une sélection de variables sur notre deuxième modèle linéaire. Toutes nos variables sont potentiellement explicatives, trouvons celles qui interviennent réellement dans l'explication de $T$.

Commençons par regarder les facteurs d'inflation de la variance (VIF), pour vérifier si nos variables explicatives ne sont pas trop corrélées entre elles. Nous allons supprimer pas à pas les variables avec un VIF trop elévé jusqu'à obtenir des VIF acceptables.

```{r vif}
vif(mod2)
```

Au vu des VIF ce dessus, nous décidons de supprimer la variable Services qui a le VIF le plus important, puis nous itérons la procédure.

```{r nouveau-modèle}
mod3 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Industrie + Taux.de.natalité, data = nouvcountries)
vif(mod3)
```

Les VIF sont à présent tous acceptables, puisqu'ils sont tous plus petit que 3.

Pouvons-nous supprimer certaines de nos variables explicatives?

Nous avons vu plus haut que la variable Densité n'était pas significative, c'est-à-dire que $\beta_2$ est proche de 0. Cependant, ce test de significativité a lieu lorsque nous prenons toutes les autres variables en compte. Dans un modèle où nous aurions retiré une autre variable, la Densité pourrait devenir significative. Nous décidons donc pour l'instant de garder toutes nos variables.

Pour faire notre selection, utilisons une procédure de modèle emboité. Comme $\beta_0$ est non nul, notre modèle contient la constante et nous pouvons nous intéresser à la maximisation de $R^2_a$ et au critère BIC (Bayesian Information Criterion).

Commençons par un modèle avec nos 6 variables explicatives.

```{r choix-modèle1, fig.width = 10, out.width = "80%"}
choix <- regsubsets(Téléphones~ Densité.population + PIB + Agriculture + Industrie + Taux.de.natalité , data = nouvcountries, nvmax = 6, really.big = T)
par(mfrow = c(1, 2))
plot(choix, sclae="bic")
plot(choix, scale="adjr2")
```

Nous décidons donc, d'après le critère BIC, de supprimer la variable Densité. Cela vient confirmer la volonté plus haut de supprimer cette variable qui n'est pas du tout corrélée à $T$ et qui avait le $\beta_j$ le plus proche de 0.

```{r choix-modèle2}
mod4 <- lm(Téléphones ~ PIB + Agriculture + Industrie + Taux.de.natalité, data = nouvcountries)
```

On itère le procédé avec nos 5 variables explicatives restantes.

```{r choix-modèle3, fig.width = 10}
choix <- regsubsets(Téléphones~ PIB + Agriculture + Industrie + Taux.de.natalité, data = nouvcountries, nvmax = 5, really.big = T)
par(mfrow = c(1, 2))
plot(choix, scale="bic")
plot(choix, scale="adjr2")
```

Au vu de nos deux graphiques, nous décidons de garder l'ensemble des variables restantes, c'est à dire le PIB, l'Agriculture, l'Industrie et le Taux de natalité.

Finalement notre modèle linéaire s'écrit:

<h4 style="text-align: center;">

Téléphones = 312,8 + 0,01 PIB - 255,4 Agriculture - 337,1 Industrie - -3,95 Taux de natalité + $\varepsilon$

</h4>

Avec $\varepsilon$ une variable aléatoire de loi normale centrée.

<br>

Nous allons à présent essayer de faire une autre régression linéaire. En effet, les VIF vus précédemment pour l'Agriculture, les Services et l'Industrie sont démesurément grands. C'est lié au fait que la somme des trois variables fait toujours 1, donc ces variables sont fortement liées. Nous avons supprimé Services en premier car son VIF était plus grand que les autres. Voyons ici ce qu'il se serait passé si nous avions plutôt retiré la variable Agriculture, qui a également un VIF très important.

```{r choix-modèle5}
mod5 <- lm(Téléphones ~ PIB + Services + Taux.de.natalité + Densité.population + Industrie, data = nouvcountries)
vif(mod5)
```

Tout nos VIF sont acceptables. Nous utilisons à nouveau une procédure de modèle emboité. Comme $\beta_0$ est non nul, notre modèle contient encore la constante et nous pouvons nous intéresser à la maximisation de $R^2_a$ et au critère BIC (Bayesian Information Criterion).

Commençons par un modèle avec nos 6 variables explicatives.

```{r choix-modèle6, fig.width = 10}
choix <- regsubsets(Téléphones~ PIB + Services + Taux.de.natalité + Densité.population + Industrie , data = nouvcountries, nvmax=6, really.big=T)
par(mfrow = c(1, 2))
plot(choix, scale="bic")
plot(choix, scale="adjr2")
```

<br>

D'après le critère BIC, nous retirons les variables Densité et Industrie, puis nous itérons la procédure.

```{r choix-modèle7, fig.width = 10}
choix <- regsubsets(Téléphones~ PIB + Services + Taux.de.natalité , data = nouvcountries, nvmax=3, really.big=T)
par(mfrow = c(1, 2))
plot(choix, scale="bic")
plot(choix, scale="adjr2")
```

<br>

Nous gardons l'intégralité des variables restantes, c'est à dire l'intercept, le PIB, les services et le taux de natalité.

```{r choix-modèle8}
mod6 <- lm(Téléphones ~ PIB + Services + Taux.de.natalité, data = nouvcountries)
summary(mod6)

```

<br>

Dans ce cas, nous avons le modèle

<h4 style="text-align: center;">

Téléphones = -8,04 + 0,01 PIB + 317,2 Services - 3,52 Taux de natalité + $\varepsilon$

</h4>

<br>

```{r téléphones-des-poissons}
tel <- df.countries$Téléphones
telp <- as.integer(tel/100)
moy <- summary(telp)["Mean"]
df.telp <- data.frame(telp)
histp <- ggplot(df.telp, aes(telp)) + geom_histogram(aes(y = stat(density)))
histp <- histp + labs(title="Comparaison histogramme-densité" ) + xlab("Nombres de téléphones scaled") + ylab("")
# histp <- histp + geom_col(aes(y = dpois(telp, lambda = moy))) + theme(plot.title = element_text(hjust = 0.5))
histp
```

```{r glm poisson}
df.countries.sans.pays$Téléphones <- telp
mdl1 <- glm(Téléphones ~ Région + PIB + Taux.de.natalité + Services, family="poisson", data = df.countries.sans.pays)
summary(mdl1)

```




puis découper le jeu de donnéés en 80 20 




