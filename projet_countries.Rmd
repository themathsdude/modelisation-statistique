---
title: Les nombres de téléphones, un nouvel indicateur de développement?
author: Justine Blanchot et Elyass Sayd, Groupe 0
date: 25/04/2022
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    theme: united
  pdf_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment = NA, echo = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.align = "center", out.width = "80%")
```

```{css layout, echo = FALSE}
h1, title, .author, .date {
  text-align: center;
}
p {
	text-indent: 20px;
}
body{
  font-size: 13pt;
}
```

<br>

## Introduction

Avant la fameuse conférence *Apple Keynote* de 2007 par Steve Jobs où il annonçait la sortie du premier iPhone, personne n'aurait pu imaginer que les écrans tactiles se retrouveraient dans toutes les mains. L'iPhone était le précurseur du marché des smartphones, marché qui a connu une des expansions les plus fulgurantes du XXe siècle. Aurions-nous pu prévoir quels marchés allaient-être les plus réceptifs à l'arrivée de cette technologie?  À l'aide de quels critères? Nous allons au fil de ce rapport nous questionner sur les corrélations possibles pour un pays donné entre le nombre de téléphones pour mille habitants et différents critères classiques de développement.

<br>

## Problématique et objectif

A partir d'un jeu de données issu de Kaggle, publié en 2017 par Fernando Lasso, intitulé "Countries of the world" et rassemblant des données du gouvernement américain (anciennes données du CIA World Factbook et International Consortium for the Advancement of Academic Publication <https://gsociology.icaap.org/dataupload.html>), nous allons nous interroger sur la présence ou non de lien entre l'implentation du marché des téléphones et les critères de développement d'un pays. 


Nous tenterons donc de répondre à la problématique suivante:

**Le nombre de téléphones portables pour mille habitants est-il un nouvel indicateur pertinent pour mesurer le développement d'un pays? Ou est-il lui même une expression de d'autres critères déjà existants?**



***

## I - Analyse descriptive des données

### A - Analyse du jeu de données

Le jeu de données que nous avons choisi contient les données de 227 pays par rapport à 19 variables. Dans le cadre de cette étude, nous nous limiterons aux variables suivantes: la région d'appartenance du pays, la densité de population (nombre d'habitants par miles carré), le PIB par habitant, le taux de natalité et, enfin, la part de la population active travaillant dans l'agriculture, l'industrie et les services. Parmi ces sept variables, six sont quantitatives et une qualitative (la région d'appartenance).

Par définition, les variables Service, Industrie et Agriculture forment une partition de la population active dans le pays. Nous décidons alors de retirer de notre étude, sans perte de précision, la variable Industrie. 

```{r installation packages, eval = FALSE, echo = FALSE}
install.packages("ggplot2")
install.packages("ggThemeAssist")
install.packages("gridExtra")
install.packages("GGally")
install.packages("carData")
install.packages("car")
install.packages("leaps")
```

```{r import-nettoyage-données}
library("ggplot2")
library("ggThemeAssist")
library("gridExtra")
library("GGally")
library("carData")
library("car")
library("leaps")
df.original <- read.csv("countries.csv", dec=",", encoding="UTF-8")
df.countries <- df.original[, c("Pays", "Téléphones", "Région", "Densité.population", "PIB", "Agriculture", "Services", "Taux.de.natalité")]
rownames(df.countries) <- df.countries$Pays
is_na = is.na(df.countries)
countries_not_na = apply(is_na, 1, sum) == 0
df.countries <- df.countries[countries_not_na, ]
```


<br>

### B - Analyse univariée de la variable d'intérêt

Introduisons des notations: 
$T$, pour téléphones, est la variables à expliquer, c'est-à-dire le nombres de téléphones pour mille habitants. 

Dans cette première partie, nous allons analyser les données de $T$. Commençons par regarder quelques caractéristiques de $T$:

```{r résumé-sommaire}
sommaire <- summary(df.countries$Téléphones)
mu = sommaire["Mean"]
sommaire
boxplot_téléphones <- ggplot(data=df.countries) + aes(y=Téléphones) + geom_boxplot() + labs(title = "Box-plot de la variable Téléphones") + theme(plot.title = element_text(hjust = 0.5))
boxplot_téléphones
```

Par lecture de notre sommaire et de notre box-plot, on obtient que la variable n'est pas symétrique, puisque la moyenne, `r round(mu,2)` est différente de la médiane,`r sommaire["Median"]`.  

Les deux indicateurs de tendance centrales sont assez bas. Le premier quartile est à `r sommaire["1st Qu."]` mais surtout le troisième quartile est égal à `r sommaire["3rd Qu."]`. Cela signifie que 75% des pays ont moins de `r sommaire["3rd Qu."]` téléphones pour mille habitants.  

L'étendue est de `r sommaire["Max."] - sommaire["Min."]`, mais cet indicateur est sensible aux valeurs aberrantes et nous voyons dans notre box-plot que nous en avons une. De plus, la longueur d'une des moustaches est assez élevée. L'écart-interquartile, plus robuste que l'étendue, est de `r sommaire["3rd Qu."] - sommaire["1st Qu."]`. Ainsi, la moitié des pays ont entre `r sommaire["1st Qu."]` et `r sommaire["3rd Qu."]` téléphones pour mille habitants.

```{r maximum}
indice_max <- which.max(df.countries$Téléphones)
ligne_max <- df.countries[indice_max,]
```

L'observation hors-norme est due aux `r ligne_max$Pays` soit les États-Unis. Ce n'est pas surprenant au vu de leur intérêt historique envers les technologies . Nous voyons sur le box-plot qu'elle n'est pas tant éloigné de la fin de la moustache.

<br>

Avant toutes recherches plus précises sur notre variable $T$, nous allons nous convaincre qu'elle est continue. Traçons sa fonction de répartition empirique.

```{r fdrplot, out.width = "70%"}
fdrplot <- ggplot(df.countries, aes(Téléphones)) + stat_ecdf(geom="step") + labs(title="Fonction de répartition empirique de T" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))
nb_sauts <- length(unique(df.countries$Téléphones))
fdrplot
```

<br>

La fonction de répartition empirique de $T$ réalise `r nb_sauts` sauts ce qui est suffisamment "grand" devant `r dim(df.countries)[1]` donc notre variable d'intérêt est continue.

Traçons son histogramme.

```{r hist-T, out.width = "70%"}
histo <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 10)
histo <- histo + labs(title="Histogramme de T", subtitles=" 10 sous-intervalles de [0,1000]" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))
histo
```

<br>

L'histogramme est uni-modal avec un pic en 0, puis à tendance décroissante. Dans notre jeu de données, beaucoup de pays ont moins de 100 téléphones pour mille habitants et à l'inverse, peu de pays ont plus de de 700 téléphones pour mille habitants.

Nous avons terminé la partie analyse univariée de notre variable d'intérêt.

<br>

### C - Analyse bi-variée

Nous allons maintenant nous intéresser aux potentielles corrélations entre notre variable d'intérêt $T$ et les autres variables de notre jeu de données.

Calculons les corrélations et présentons un diagramme de dispersion de toutes les paires de variables, pour chaque variable quantitative de notre jeu de données.

```{r corrélations-df, results = 'hide', out.width = "70%"}

df.countries.sans.pays <- df.countries[, -c(1)]
df.countries.sans.pays.region <- df.countries.sans.pays[, -c(2)]
ggpairs1 <- ggpairs(df.countries.sans.pays.region[, c(1:3,6)])
ggpairs2 <- ggpairs(df.countries.sans.pays.region[, c(1,4:5)])

cor(df.countries.sans.pays.region)
ggpairs1
ggpairs2
```

On a un facteur de corrélation d'environ 0.85 pour le couple de variables $T$ et PIB; on en déduit qu'elles sont fortement corrélées linéairement. Il en est de même pour les variables Services et $T$ avec un facteur de corrélation de 0.68. Finalement, la variable $T$ est également corrélée négativement à la variable Agriculture avec un coefficient de corrélation de -0,62 et à la variable Taux de natalité avec un coefficient de -0,73.

Analysons maintenant les nuages de points des paires de variables:

-   ($T$, Densité de population): la tendance semble montrer une corrélation, mais c'est peut être l'effet de certaines observations très grandes, qui ont écrasé un nuage de points qui aurait semblé aléatoire. Le coefficient est en lui même faible.

-   ($T$, PIB): les points sont relativement alignés sur une droite, ce qui est cohérent avec le coefficient de corrélation.

-   ($T$, Taux de natalité): les points ont l'air concentré dans une région du plan sous une hyperbole et dans le premier quart du plan. Le modèle idéal n'est peut être pas linéaire pour cette variable.

-   ($T$, Agriculture): même remarque que pour le taux de natalité.

-   ($T$, Services): ici la tendance est marquée sur le nuage, avec un grand coefficient de corrélation.

<br>

Nous avons maintenant une idée plus claire des liens entre notre variables d'intérêt et les variables quantitatives de notre jeu de données.

Terminons cette partie en nous intéressant à la variables Région, qui est une variable qualitative. Traçons le boxplot de la variable $T$ pour chaque modalité de la variable Région.

```{r boxplot-régions, out.width = "70%"}
boxplot_region <- ggplot(data=df.countries) + aes(x=as.factor(Région), y=Téléphones) + scale_x_discrete(guide = guide_axis(n.dodge=4)) + geom_boxplot() + xlab("Régions")
boxplot_region
```

Les boxplots sont très différents, la région d'appartenance du pays semble joue un rôle important sur $T$. On remarque qu'en Amérique du nord et en Europe de l'ouest, les médianes régionales sont hautes. Ces dernières sont beaucoup plus basses en Afrique Sub-saharienne, en Océanie ou encore en Asie. Il y a parfois des observations hors-normes, notamment en Afrique sub-saharienne. Ces observations  atypiques pourraient jouer un rôle sur notre modélisation de $T$. Nous y reviendrons, ci-besoin, plus loin dans notre rapport.

<br>

## II - Régression linéaire multiple

### A - Modèle général

Dans cette partie, nous allons nous intéresser à une régression linéaire permettant d'exprimer la variable $T$ par la densité de population, le PIB par habitant, le taux de natalité et enfin la part de la population active travaillant dans l'agriculture et les services.

On considère le modèle linéaire suivant:

<h4 style="text-align: center;">
Téléphones = $\beta_0$ + $\beta_1$Densité + $\beta_2$PIB + $\beta_3$ Agriculture + $\beta_4$Services +  $\beta_5$Taux de natalité + $\varepsilon$
</h4>

Nous avons déjà une première idée des corrélations linéaires de nos variables grâce à l'analyse bi-variée. Formalisons ces relations et trouvons les coefficients $\beta_j$. Dans le but de pouvoir comparer les $\beta_j$, nous devons centrer-réduire nos données.  
Réaliser une  première régression sur notre jeu de données centré-réduit.


```{r sommaire-régression}
df.countries.scale<-df.countries
df.countries.scale[,c(2,4:8)] <- scale(df.countries[,c(2,4:8)])
df.countries.scale <- as.data.frame(df.countries.scale)

mod1 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Services + Taux.de.natalité, data = df.countries.scale)
summary_mod1 <- summary(mod1)
summary_mod1
```

Analysons ce sommaire. Le $R^2$ vaut `r round(summary_mod1$r.squared,2)` qui est proche de 1 avec une p-valeur associée très faible, donc on rejette l'hypothèse selon laquelle tous les $\beta_j$ sont nuls pour $j=0,...,5$. Le modèle de régression linéaire permet d'expliquer relativement bien notre variable $T$.

De plus, les tests de significativité des coefficients $\beta_2$, $\beta_4$,  et $\beta_5$ donnent des p-valeurs inférieures à 0.001, donc $\beta_2$, $\beta_4$,  et $\beta_5$ sont non nuls.

Regardons d'un peu plus près toutes nos obeservations. 

<br>

### B - Analyse des résidus

Nous allons vérifier que nos obeservations sont de "bonnes qualités" en cherchant si nous avons des valeurs aberrantes, des points leviers ou des distance de Cook trop élevées. Commençons par les valeurs aberrantes et les points leviers.

```{r résidus-student-levier, fig.width = 11}
df.residus <- data.frame(residu = rstudent(mod1))
n <- length(df.countries$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
# n-p-1=203 >30 donc OK de prendre 2
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupes <- rep("Valeur non aberrante", n)
df.residus[ID_suspect, ]$Groupes <- "Valeur aberrante"

plot_rstudent <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupes) + geom_point()
plot_rstudent <- plot_rstudent + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_text(aes(label=ID), hjust = 0, vjust = 0)
plot_rstudent <- plot_rstudent + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes") + theme(plot.title = element_text(hjust = 0.5))

nb_aberrant <- sum(abs(df.residus$residu) > 2)

# Points leviers
p <- mod1$rank
# p vaut 6 donc on regarde surtout le seuil de Hoaglin & Welsch soit le seuil 1
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod1))
ID_levier <- (1:n)[df.H$H>seuil1]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupes <- rep("Point non levier", n)
df.H[ID_levier, ]$Groupes <- "Point levier"

plot_levier <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupes) + geom_point()
plot_levier <- plot_levier + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier <- plot_levier + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier <- plot_levier + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier <- plot_levier + xlab('Index') + ylab('hii') + labs(title="Analyse des points levier") + theme(plot.title = element_text(hjust = 0.5))

nb_leviers <- sum(df.H$H > seuil1)

grid.arrange(plot_levier , plot_rstudent, widths = c(1/2, 1/2))
```

On a `r nb_aberrant` valeurs aberrantes dans un échantillon de taille `r dim(df.countries)[1]` donc `r round(nb_aberrant*100/dim(df.countries)[1],2)` des résidus studentisés $t_i^*$ ne se trouvent pas dans l'intervalle [−2,2], soit une proportion acceptable (moins de 5%). De plus, il y a `r nb_leviers` points leviers qui dépassent le deuxième seuil. Parmi les points leviers, l'observation 115, qui est le Luxembourg, est également une observation aberrante. Vérifions à présent les distances de Cook.

```{r dist.cook, out.width = "70%"}
df.cook <- data.frame(cook = cooks.distance(mod1))
s1 <- qf(0.1, p, n-p)
s2 <- qf(0.5, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 3)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 2)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analyse des distances de Cook") + theme(plot.title = element_text(hjust = 0.5))
plot_cook

l <- which.max(cooks.distance(mod1))
```

Aucune valeur n'a une distance de Cook supérieure au deuxième seuil. L'observation qui a la distance de Cook la plus élevée est l'observation `r l` soit le Luxembourg, mais sa distance de Cook ne dépassant pas le deuxième seuil nous décidons de la garder.

Nos observations sont de "bonne qualité". Nous pouvons donc réaliser une sélection de variables.


<br>

### C - Sélection de variables

Toutes nos variables sont potentiellement explicatives, trouvons celles qui interviennent réellement dans l'explication de $T$.

Commençons par regarder les facteurs d'inflation de la variance (VIF), pour vérifier si nos variables explicatives ne sont pas trop corrélées entre elles.

```{r vif}
vif(mod1)
```

Tout nos VIFS sont acceptables (inférieurs à 3). 

Pour faire notre sélection parmi les variables restantes, nous allons utiliser une procédure de modèle emboîté. Comme notre modèle contient la constante, nous pouvons nous intéresser à la maximisation de $R^2_a$ et au critère BIC (Bayesian Information Criterion).
 
Commençons par un modèle avec nos 5 variables explicatives.

```{r choix-modèle1, fig.width = 10, out.width = "80%"}
choix1 <- regsubsets(Téléphones~ Densité.population + PIB + Agriculture + Taux.de.natalité , data = df.countries.scale, nvmax = 5, really.big = T)
par(mfrow = c(1, 2))
plot(choix1, sclae="bic")
plot(choix1, scale="adjr2")
```

Nous supprimons alors les variables Densité et Agriculture.

```{r mod2}
mod2 <- lm(Téléphones ~ PIB + Services + Taux.de.natalité, data = df.countries.scale)
```

On itère le procédé avec nos 3 variables explicatives restantes.

```{r choix-modèle2, fig.width = 10, out.width = "80%"}
choix2 <- regsubsets(Téléphones~ PIB + Services + Taux.de.natalité , data = df.countries.scale, nvmax=3, really.big=T)
par(mfrow = c(1, 2))
plot(choix2, scale="bic")
plot(choix2, scale="adjr2")
```

Nous gardons l'ensemble des variables restantes, c'est à dire le PIB, les Services et le Taux de natalité.

```{r modèle-choisi}
mod_choisi <- mod2
summary(mod_choisi)
```

Finalement, après l'étape de sélection, notre modèle linéaire s'écrit:

<h4 style="text-align: center;">

Téléphones = `r round(mod_choisi$coefficients['PIB'],2)` PIB + `r round(mod_choisi$coefficients['Services'],2)` Services - `r abs(round(mod_choisi$coefficients['Taux.de.natalité'],2))` Taux de natalité + $\varepsilon$

</h4>

Avec $\varepsilon$ une variable aléatoire centrée.

<br>

### D - Validation du modèle

Nous allons vérifier à nouveau que nous n'avons pas de valeurs problématiques en regardant les valeurs aberrantes, les points leviers et les distances de Cook.

```{r residus-student3, fig.width = 11, out.width = "70%"}
df.residus <- data.frame(residu = rstudent(mod_choisi))
n <- length(df.countries.scale$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
# n-p-1=203 >30 donc OK de prendre 2
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupes <- rep("Valeur non aberrante", n)
df.residus[ID_suspect, ]$Groupes <- "Valeur aberrante"

plot_rstudent <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupes) + geom_point()
plot_rstudent <- plot_rstudent + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent <- plot_rstudent + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes") + theme(plot.title = element_text(hjust = 0.5))

nb_aberrant2 <- sum(abs(df.residus$residu) > 2)

# Points leviers
p <- mod_choisi$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod_choisi))
ID_levier <- (1:n)[df.H$H > seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupes <- rep("Point non levier", n)
df.H[ID_levier, ]$Groupes <- "Point levier"

plot_levier <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupes) + geom_point()
plot_levier <- plot_levier + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier <- plot_levier + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier <- plot_levier + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier <- plot_levier + xlab('Index') + ylab('hii') + labs(title="Analyse des points levier") + theme(plot.title = element_text(hjust = 0.5))


nb_leviers2 <- sum(df.H$H>seuil2)

df.cook <- data.frame(cook = cooks.distance(mod_choisi))
s1 <- qf(0.1, p, n-p)
s2 <- qf(0.5, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 3)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 2)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analyse des distances de Cook") + theme(plot.title = element_text(hjust = 0.5))


l<- which.max(cooks.distance(mod_choisi))

grid.arrange(plot_rstudent, plot_levier, widths = c(1/2, 1/2))
plot_cook
```

On a `r nb_aberrant2` valeurs aberrantes dans un échantillon de taille `r dim(df.countries)[1]` donc `r round(nb_aberrant2*100/dim(df.countries)[1],2) `% des résidus studentisés $t_i^*$ ne se trouvent pas dans l'intervalle [−2,2]. C'est une proportion acceptable, car inférieure à 5%. Il y a `r nb_leviers2` points leviers qui dépassent le deuxième seuil. Parmi eux, l'observation 115, qui est le Luxembourg, est également une observation aberrante. De plus, le Luxembourg a  une distance de Cook qui dépasse le seuil préoccupant (`r s2`). Nous décidons donc de supprimer cette observation et de réaliser une nouvelle régression linéaire.

```{r sans-le-Luxembourg}
nouvcountries <- df.countries.scale[c(-115), ]
mod_affiné <- lm(Téléphones ~  PIB + Services + Taux.de.natalité, data = nouvcountries)
summary(mod_affiné)
```

Ainsi, après la sélection de variable et l'étude des observations, on en déduit que notre modèle linéaire s'écrit :

<h4 style="text-align: center;">
Téléphones = `r round(mod_affiné$coefficients['PIB'],2)` PIB + `r round(mod_affiné$coefficients['Services'],2)` Services - `r abs(round(mod_affiné$coefficients['Taux.de.natalité'],2))` Taux de natalité + $\varepsilon$
</h4>


Nous avons centré et réduit nos observations donc nos coefficients $\beta_j$ sont comparables. Dans notre modèle linéaire, c'est le PIB du pays qui influence le plus $T$. La part de la population dans les services inflence également positivement $T$, même si cette influence est moindre. Finalement, le taux de natalité du pays infleunce également $T$ mais cette fois-ci négativement.

Notons que les coefficients diffèrent des coefficients précédents lorsqu'on avait gardé le Luxembourg, notamment le coefficient devant le PIB et celui devant le taux de natalité. 

À présent, nous allons réaliser une analyse de la normalité des résidus, pour vérifier si notre modèle linéaire est bien Gaussien. Traçons un QQ-plot qui compare les quantiles empiriques associés aux studentisés ($t_1^*,...,t_n^*$) aux quantiles de la loi de Student $\mathcal{T}(n-p-1)$ pour valider l'hypothèse que les résidus suivent une loi normale.

```{r qqplot-residus, out.width = "70%"}
n <- length(nouvcountries$Téléphones)
p <- mod_affiné$rank
df.residus2 <- data.frame(residu = rstudent(mod_affiné))

quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs = sort(df.residus2$residu), Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)") + labs(title="QQ-plot quantiles des studentisés contre quantiles théoriques") + theme(plot.title = element_text(hjust = 0.5))
qq.plot
```

Le QQ-plot des résidus studentisés contre les quantiles d'une loi de Student de degrés de liberté n-p-1 =`r n-p-1` semble raisonnable.
Nous validons l'hypothèse de la normalité des résidus. Notre modèle linéaire est donc Gaussien.

<br>

## III - Analyse de la variance

### A - Modélisation 

La partie précédente nous a montré qu'un modèle linéaire explique relativement bien $T$. Dans cette partie, nous allons nous intéresser à l'importance de la région dans l'explication de $T$.
Ajoutons une nouvelle variable, cette fois-ci qualitative, et potentiellement explicative de $T$ : la Région d'appartenance du pays. Nous gardons nos trois variables quantitatives précédentes (pour se limiter à une étude de taille acceptable) soit le PIB, le taux de natalité et la proportion de la population dans les services.

Nous avons observé dans la partie analyse bi-variée que la région d'appartenance du pays influe sur $T$ (cf. Box-plot par région). Nous voudrions donc savoir à quel point cette influence est forte, et s'il existe des effet d'interaction entre nos variables explicatives.

Nous allons réaliser une ANCOVA sur notre jeu de données centré-réduit. 

```{r summary-complet}
complet <- lm(Téléphones ~ Région, data = df.countries)
summary_complet <- summary(complet)
summary_complet
```

</details>

Pour le modèle complet, le $R^2$ égal à `r round(summary_complet$r.squared, 2)` et la p-valeur du test global de Fisher indique que le modèle explique mieux la réalité que le modèle contenant uniquement la constante. 

Nous allons maintenant réaliser une sélection de variables. 

```{r ancova}
anova(complet)
```

L’interaction entre la région et le taux de natalité ainsi que l'intéraction entre la région et la variables Services n'ont pas d'effet sur $T$, nous les supprimons. 
 
```{r mod-sans-int}
mod.sans.int <- lm(Téléphones~ Région + Services + Taux.de.natalité + PIB + Région*PIB, data= df.countries.scale)
anova(mod.sans.int)
mod.retenu <- mod.sans.int
```


Toutes les variables et interactions restantes sont significatives. La probabilité critique associée à la variable région est inférieure à 0.1%. On rejette donc l'hypothèse que la région d'appartenance du pays n'a pas d'effet sur $T$. Les variables PIB, Services et Taux de natalité ont encore un effet sur $T$ et il y a un effet d'interaction entre Région et le PIB. 


### B- Analyse des résidus

Commençons par regarder si nous avons des valeurs aberrantes et des points leviers. 

```{r residus-student, fig.width = 11}
df.residus <- data.frame(pays = df.countries$Pays, residu = rstudent(mod.retenu))
n <- length(df.countries$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
ID_suspect <- ID_suspect[!is.na(ID_suspect)]
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupe <- rep("Non aberrante", n)
df.residus[ID_suspect, ]$Groupe <- "Aberrante"

plot_rstudent2 <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupe) + geom_point()
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent2 <- plot_rstudent2 + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes, ANCOVA") + theme(plot.title = element_text(hjust = 0.5))


nb_aberrant3 <- sum(abs(df.residus$residu) > 2)

p <- mod.retenu$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod.retenu))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupe <- rep("Non levier", n)
df.H[ID_levier, ]$Groupe <- "Levier"

plot_levier2 <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupe) + geom_point()
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier2 <- plot_levier2 + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier2 <- plot_levier2 + xlab('Index') + ylab('hii') + labs(title="Analayse des points levier, ANCOVA") + theme(plot.title = element_text(hjust = 0.5))


grid.arrange(plot_rstudent2, plot_levier2, widths = c(1/2, 1/2))

nb_leviers3 <- sum(abs(hatvalues(mod.retenu) > seuil2))
```

Nous avons `r nb_aberrant3` valeurs aberrantes, soit `r round((nb_aberrant3/n)*100,2)` % de nos observations ne sont pas dans l'intervalle [-2;2] ce qui est acceptable (moins de 5%). Nous avons `r nb_leviers3` points leviers. Aucune observation n'est à la fois levier et aberrante. Analysons à présent les distances de Cook. 
 
```{r df-cook-anov, out.width = "70%"}
df.cook <- data.frame(cook = cooks.distance(mod.retenu))
s1 <- qf(0.5, p, n-p)
s2 <- qf(0.1, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 2)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 3)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analayse des distances de Cook, ANCOVA") + theme(plot.title = element_text(hjust = 0.5))
plot_cook
```

Aucune distance de Cook ne dépasse le premier seuil et à fortiori le deuxième. Nous pouvons donc garder toutes nos observations. 
 
Finalisons cette analyse en vérifiant l'hypothèse de normalité des résidus. 
 
```{r normalité-résidus, out.width = "70%"}
quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs = df.residus$residu[order(df.residus$residu)], Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)") + labs(title="QQ-plot quantiles des résidus studentisés contre quantiles théoriques, ANCOVA") + theme(plot.title = element_text(hjust = 0.5))
qq.plot
```

On peut valider l'hypothèse selon laquelle les résidus sont gaussiens. 
Pour conclure, on accepte notre modélisation du problème
<br>



### C - Conclusion de l'ANCOVA

 L'ANCOVA nous a confirmé la pertinence de notre modèle linéaire, mais  elle ne permets pas d'expliquer spécialement mieux nos données. En effet, nous ajoutons une variable a prendre en compte et nous n'obtenons pas une modélisation beaucoup plus précise. Ceci est du au fait que la région d'appartenance du pays est une variable déductible en grnde partie des autres variables d'intérêt choisies.


## Conclusion générale

  Au fil de cette analyse,  nous nous sommes rendus compte que le nombre de téléphones pour mille habitants est corrélé aux indicateurs dits classiques de développement. En effet, en 2000, le PIB, le taux de natalités et la part de la population dans les services suffisaient à prédire cette variable. Ainsi, le nombre de téléphones pour mille habitants n'ajoute pas une donnée suffisament pertinente lors d'une analyse de développement d'un pays. 
  
  Quand serait-il aujourd'hui? Le nombre de téléphones pour mille habitants a explosé dans tous les pays. En France, 54 millions de personnes en 2020 possédaient un smartphone (chiffre de l'Arcep, l'Autorité de régulation des communications électroniques) pour 67 millions d'habitants (chiffre de l'INSEE). On a donc un taux de 800 téléphones pour mille habitants. Nous n'étions qu'à 586 en 2000. Cette explosion n'a pas eu lieu que dans les pays développés. Les smartphones ont pénétrés les marchés des pays en développement au point d'avoisiner des taux rencontrés dans les pays développés. Pourtant, les critères comme le PIB et le taux de natalités ne se sont pas harmonisés au niveau mondial. 
  
  L'explication linéaire du nombre de téléphones pour mille habitants par les critères de développement serait-elle encore pertinente aujourd'hui?
  
  

<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>


## Annexe


### Analyse uni-variéé, adéquation à une loi

Au vu de l'histogramme de $T$, nous pouvions penser que $T$ etait un échantillon de loi exponentielle, c'est-à-dire que $T$ est la réalisation d'une variable aléatoire  $X$ suivant une loi exponentielle de paramètre $\lambda$. La méthode des moments nous propose la moyenne empirique de $T$ comme estimateur sans biais, consistant et asymptotiquement normal de l'espérance.

La moyenne empirique de $T$ est $\mu =$ `r mu`. En prenant $\hat \lambda =$ `r 1/mu`, nous voulons vérifier que notre hypothèse est acceptable. Nous allons alors tracer le QQ-plot entre les quantiles théoriques de $X$  et les quantiles empiriques de $T$. 


```{r T-exponentielle, fig.height = 6, fig.width = 8, out.width = "70%"}

df.qq <- data.frame(df.countries$Téléphones)
names(df.qq) <- "Téléphones"
df.qq$Téléphones <- df.qq$Téléphones/mu
qqplot <- ggplot(data = df.qq, aes(sample = Téléphones)) + stat_qq(distribution = stats::qexp)
qqplot <- qqplot + geom_abline(intercept = 0,slope = 1, col = "blue") + labs(title="Diagramme quantile-quantile") + xlab("Quantiles théoriques") + ylab("Quantiles obeservés") + theme(plot.title = element_text(hjust = 0.5))
qqplot

```

Les points de notre QQ-plot s'alignent bien sur la première bissectrice. C'est encourageant. L'adéquation n'est pas parfaite mais elle est suffisamment raisonnable pour retenir l'hypothèse que $T$ suit une loi exponentielle de paramètre $\hat \lambda$. 

Nous allons finaliser notre analyse univariée en réalisant un test de Kolmogorov-Smirnov sur notre échantillon, puisque la variable Téléphones et la loi exponentielle sont toutes deux de lois continues. 
   
```{r test-T}
rexpsample <- df.countries$Téléphones/mu
kstest <- ks.test(df.countries$Téléphones, rexpsample)
kstest
p <- kstest$p.value
```

Notre p-valeur est inférieure à 2.2e-16 donc on rejette $H_0$ au profit de l'hypothèse alternative $H_1$ sans hésitation. On peut conclure que notre variable $T$ ne suit pas une loi exponentielle de paramètre $\hat\lambda$. $T$ est la réalisation d'une autre loi, dont on ne connait pas la nature exacte.



<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>


