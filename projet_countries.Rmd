---
title: Le nombre de téléphones, un nouvel indicateur de développement?
author: Justine Blanchot et Elyass Sayd, Groupe 0
date: Vendredi 13 Mai 2022
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    theme: united
  pdf_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment = NA, echo = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.align = "center", out.width = "80%")
```

```{css layout, echo = FALSE}
h1, title, .author, .date {
  text-align: center;
}
p {
	text-indent: 20px;
}
body{
  font-size: 13pt;
  text-align: justify;
}
```

<br>

## Introduction

Avant la fameuse conférence *Apple Keynote* de 2007 par Steve Jobs où il annonçait la sortie du premier iPhone, personne n'aurait pu imaginer que les écrans tactiles se retrouveraient dans toutes les mains. L'iPhone était le précurseur du marché des smartphones, marché qui a connu une des expansions les plus fulgurantes du XXIe siècle. Aurions-nous pu prévoir quels marchés allaient-être les plus réceptifs à l'arrivée de cette technologie?  À l'aide de quels critères? Nous allons au fil de ce rapport nous questionner sur les corrélations possibles pour un pays donné entre le nombre de téléphones pour mille habitants et différents critères classiques de développement.

<br>

## Problématique et objectif

A partir d'un jeu de données issu de Kaggle, publié en 2017 par Fernando Lasso, intitulé "Countries of the world" et rassemblant des données du gouvernement américain (anciennes données du CIA World Factbook et International Consortium for the Advancement of Academic Publication <https://gsociology.icaap.org/dataupload.html>), nous allons nous interroger sur la présence ou non de lien entre l’implantation du marché des téléphones et les critères de développement d'un pays. 


Nous tenterons de répondre à la problématique suivante :

<div style="border:3px; border-style:solid; border-color:#FF0000; padding: 1em;">
**Le nombre de téléphones portables pour mille habitants est-il un nouvel indicateur pertinent pour mesurer le développement d'un pays? Ou est-il lui-même une expression  d'autres critères déjà existants?**
</div>

***

## I - Analyse descriptive des données

### A - Analyse du jeu de données

Le jeu de données que nous avons choisi contient les données de 227 pays par rapport à 19 variables. Dans le cadre de cette étude, nous nous limiterons aux variables suivantes : la région d'appartenance du pays, la densité de population (nombre d'habitants par miles carré), le PIB par habitant, le taux de natalité et enfin, la part de la population active travaillant dans l'agriculture, l'industrie et les services. Parmi ces sept variables, nous en avons six quantitatives et une qualitative (la région d'appartenance).

Par définition, les variables Service, Industrie et Agriculture forment une partition de la population active dans le pays. Nous décidons alors de retirer de notre étude, sans perte de précision, la variable Industrie. 

```{r installation-packages, eval = FALSE, echo = FALSE}
install.packages("ggplot2")
install.packages("ggThemeAssist")
install.packages("gridExtra")
install.packages("GGally")
install.packages("carData")
install.packages("car")
install.packages("leaps")
```

```{r import-nettoyage-données}
library("ggplot2")
library("ggThemeAssist")
library("gridExtra")
library("GGally")
library("carData")
library("car")
library("leaps")
df.original <- read.csv("countries.csv", dec=",", encoding="UTF-8")
df.countries <- df.original[, c("Pays", "Téléphones", "Région", "Densité.population", "PIB", "Agriculture", "Services", "Taux.de.natalité")]
rownames(df.countries) <- df.countries$Pays
is_na = is.na(df.countries)
countries_not_na = apply(is_na, 1, sum) == 0
df.countries <- df.countries[countries_not_na, ]
```


<br>

### B - Analyse univariée de la variable d'intérêt

Introduisons une notation : 

$T$, pour téléphones, est la variables à expliquer, c'est-à-dire le nombre de téléphones pour mille habitants. 

Dans cette première partie, nous allons analyser les données de $T$. Commençons par regarder quelques caractéristiques :

```{r résumé-sommaire}
sommaire <- summary(df.countries$Téléphones)
mu = sommaire["Mean"]
sommaire
boxplot_téléphones <- ggplot(data=df.countries) + aes(y=Téléphones) + geom_boxplot() + labs(title = "Boxplot de la variable Téléphones") + theme(plot.title = element_text(hjust = 0.5))
boxplot_téléphones
```

Par lecture de notre sommaire et de notre boxplot, on obtient que la variable n'est pas symétrique, puisque la moyenne, `r round(mu, 2)` est différente de la médiane,`r sommaire["Median"]`.  

Les deux indicateurs de tendance centrale sont assez bas. Le premier quartile est à `r sommaire["1st Qu."]` mais surtout le troisième quartile est égal à `r sommaire["3rd Qu."]`. Cela signifie que 75% des pays ont moins de `r sommaire["3rd Qu."]` téléphones pour mille habitants.  

L'étendue est de `r sommaire["Max."] - sommaire["Min."]`, mais cet indicateur est sensible aux valeurs aberrantes et nous voyons dans notre boxplot que nous en avons une. De plus, la longueur d'une des moustaches est assez élevée. L'écart-interquartile, plus robuste que l'étendue, est de `r sommaire["3rd Qu."] - sommaire["1st Qu."]`. Ainsi, la moitié des pays ont entre `r sommaire["1st Qu."]` et `r sommaire["3rd Qu."]` téléphones pour mille habitants.

```{r maximum}
indice_max <- which.max(df.countries$Téléphones)
ligne_max <- df.countries[indice_max,]
```

L'observation hors-norme est due aux `r ligne_max$Pays` soit les États-Unis. Ce n'est pas surprenant au vu de leur intérêt historique envers les technologies . Nous voyons sur le boxplot qu'elle n'est pas tant éloignée de la fin de la moustache.

<br>

Avant toute recherche plus précise sur notre variable $T$, nous allons nous convaincre qu'elle est continue. Traçons sa fonction de répartition empirique.

```{r fdrplot}
fdrplot <- ggplot(df.countries, aes(Téléphones)) + stat_ecdf(geom="step") + labs(title="Fonction de répartition empirique de T" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))
nb_sauts <- length(unique(df.countries$Téléphones))
fdrplot
```

<br>

La fonction de répartition empirique de $T$ réalise `r nb_sauts` sauts ce qui est suffisamment "grand" devant `r dim(df.countries)[1]` (le nombre d'observations) donc notre variable d'intérêt est continue.

Traçons son histogramme.

```{r hist-T}
histo <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 10)
histo <- histo + labs(title="Histogramme de T", subtitles=" 10 sous-intervalles de [0,1000]" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))
histo
```

<br>

L'histogramme est unimodal avec un pic en 0, puis à tendance décroissante. Dans notre jeu de données, beaucoup de pays ont moins de 100 téléphones pour mille habitants et à l'inverse, peu de pays ont plus de de 700 téléphones pour mille habitants.

Nous avons terminé la partie analyse univariée de notre variable d'intérêt.

<br>

### C - Analyse bivariée

Nous allons maintenant nous intéresser aux potentielles corrélations entre notre variable d'intérêt $T$ et les autres variables de notre jeu de données.

Calculons les corrélations et présentons un diagramme de dispersion de toutes les paires de variables, pour chaque variable quantitative de notre jeu de données.

```{r corrélations-df, results = 'hide', out.width = "100%"}

df.countries.sans.pays <- df.countries[, -c(1)]
df.countries.sans.pays.region <- df.countries.sans.pays[, -c(2)]
ggpairs1 <- ggpairs(df.countries.sans.pays.region[, c(1:3,6)])
ggpairs2 <- ggpairs(df.countries.sans.pays.region[, c(1,4:5)])

cor(df.countries.sans.pays.region)
ggpairs1
ggpairs2
```

On a un facteur de corrélation d'environ 0.85 pour le couple de variables $T$ et PIB; on en déduit qu'elles sont fortement corrélées. Il en est de même pour les variables Services et $T$ avec un facteur de corrélation de 0.68. De plus, la variable $T$ est également corrélée négativement à la variable Agriculture avec un coefficient de corrélation de -0,62 et à la variable Taux de natalité avec un coefficient de -0,73.

Analysons maintenant les nuages de points des paires de variables :

-   ($T$, Densité de population) : la tendance semble montrer une corrélation, mais c'est peut être l'effet de certaines observations très grandes, qui ont écrasé un nuage de points qui aurait semblé aléatoire. Le coefficient est en lui même faible.

-   ($T$, PIB) : les points sont relativement alignés sur une droite, ce qui est cohérent avec le coefficient de corrélation.

-   ($T$, Taux de natalité) : les points ont l'air concentrés dans une région du plan sous une hyperbole et dans le premier quart du plan. Le modèle idéal n'est peut être pas linéaire pour cette variable.

-   ($T$, Agriculture) : même remarque que pour le taux de natalité.

-   ($T$, Services) : ici la tendance est marquée sur le nuage, avec un grand coefficient de corrélation.

<br>

Nous avons maintenant une idée plus claire des liens entre notre variables d'intérêt et les variables quantitatives de notre jeu de données.

Terminons cette partie en nous intéressant à la variables Région, qui est une variable qualitative. Traçons le boxplot de la variable $T$ pour chaque modalité de la variable Région.

```{r boxplot-régions, out.width = "100%"}
boxplot_region <- ggplot(data=df.countries) + aes(x=as.factor(Région), y=Téléphones) + scale_x_discrete(guide = guide_axis(n.dodge=4)) + geom_boxplot() + xlab("Régions")
boxplot_region
```

Les boxplots sont très différents, la région d'appartenance du pays semble jouer un rôle important sur $T$. On remarque qu'en Amérique du Nord et en Europe de l'Ouest, les médianes régionales sont hautes. Ces dernières sont beaucoup plus basses en Afrique subsaharienne, en Océanie ou encore en Asie. Il y a parfois des observations hors-normes, notamment en Afrique subsaharienne. Ces observations  atypiques pourraient jouer un rôle sur notre modélisation de $T$. Nous y reviendrons, ci-besoin, plus loin dans notre rapport.

<br>

## II - Régression linéaire multiple

### A - Modèle général

Dans cette partie, nous allons nous intéresser à une régression linéaire permettant d'exprimer la variable $T$ en fonction de la densité de population, le PIB par habitant, le taux de natalité et enfin la part de la population active travaillant dans l'agriculture et les services.
On considère le modèle linéaire suivant :

<h4 style="text-align: center;">
Téléphones = $\beta_0$ + $\beta_1$Densité + $\beta_2$PIB + $\beta_3$ Agriculture + $\beta_4$Services +  $\beta_5$Taux de natalité + $\varepsilon$
</h4>

Nous avons déjà une première idée des corrélations entre nos variables grâce à l'analyse bivariée. Formalisons ces relations et trouvons les coefficients $\beta_j$ et la loi d' $\varepsilon$. Dans le but de pouvoir comparer les $\beta_j$, nous devons centrer-réduire nos données.  
Réalisons une première régression sur notre jeu de données centré-réduit.


```{r sommaire-régression}
df.countries.scale <- df.countries
df.countries.scale[,c(2,4:8)] <- scale(df.countries[,c(2,4:8)])
df.countries.scale <- as.data.frame(df.countries.scale)

mod1 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Services + Taux.de.natalité, data = df.countries.scale)
summary_mod1 <- summary(mod1)
summary_mod1
```

Le $R^2$ vaut `r round(summary_mod1$r.squared,2)` qui est proche de 1 avec une p-valeur associée très faible, donc on rejette l'hypothèse selon laquelle tous les $\beta_j$ sont nuls pour $j=0,...,5$. Le modèle de régression linéaire permet d'expliquer relativement bien notre variable $T$.

De plus, les tests de significativité des coefficients $\beta_2$, $\beta_4$, et $\beta_5$ donnent des p-valeurs inférieures à 0.001, donc $\beta_2$, $\beta_4$, et $\beta_5$ sont non nuls.

Regardons d'un peu plus près toutes nos observations. 

<br>

### B - Analyse des résidus

Nous allons vérifier que nos observations sont de "bonne qualité" en cherchant si nous avons des valeurs aberrantes, des points leviers ou des distances de Cook trop élevées. Commençons par les valeurs aberrantes et les points leviers.

```{r résidus-student-levier, fig.width = 11, out.width = "100%"}
df.residus <- data.frame(residu = rstudent(mod1))
n <- length(df.countries$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
# n-p-1=203 >30 donc OK de prendre 2
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupes <- rep("Valeur non aberrante", n)
df.residus[ID_suspect, ]$Groupes <- "Valeur aberrante"

plot_rstudent <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupes) + geom_point()
plot_rstudent <- plot_rstudent + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_text(aes(label=ID), hjust = 0, vjust = 0)
plot_rstudent <- plot_rstudent + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes") + theme(plot.title = element_text(hjust = 0.5))

nb_aberrant <- sum(abs(df.residus$residu) > 2)

# Points leviers
p <- mod1$rank
# p vaut 6 donc on regarde surtout le seuil de Hoaglin & Welsch soit le seuil 1
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod1))
ID_levier <- (1:n)[df.H$H>seuil1]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupes <- rep("Point non levier", n)
df.H[ID_levier, ]$Groupes <- "Point levier"

plot_levier <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupes) + geom_point()
plot_levier <- plot_levier + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier <- plot_levier + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier <- plot_levier + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier <- plot_levier + xlab('Index') + ylab('hii') + labs(title="Analyse des points levier") + theme(plot.title = element_text(hjust = 0.5))

nb_leviers <- sum(df.H$H > seuil1)

grid.arrange(plot_levier , plot_rstudent, widths = c(1/2, 1/2))
```

On a `r nb_aberrant` valeurs aberrantes dans un échantillon de taille `r dim(df.countries)[1]` donc `r round(nb_aberrant*100/dim(df.countries)[1],2)`% des résidus studentisés $t_i^*$ ne se trouvent pas dans l'intervalle [−2,2], soit une proportion acceptable (moins de 5%). De plus, il y a `r nb_leviers` points leviers qui dépassent le deuxième seuil. Parmi les points leviers, l'observation 115, qui est le Luxembourg, est également une observation aberrante. Vérifions à présent les distances de Cook.

```{r dist.cook}
df.cook <- data.frame(cook = cooks.distance(mod1))
s1 <- qf(0.1, p, n-p)
s2 <- qf(0.5, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 3)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 2)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analyse des distances de Cook") + theme(plot.title = element_text(hjust = 0.5))
plot_cook

l <- which.max(cooks.distance(mod1))
```

Aucune valeur n'a une distance de Cook supérieure au deuxième seuil. L'observation qui a la distance de Cook la plus élevée est l'observation `r l` soit le Luxembourg, mais sa distance de Cook ne dépassant pas le deuxième seuil nous décidons de la garder.

Nos observations sont de "bonne qualité". Nous pouvons donc réaliser une sélection de variables.


<br>

### C - Sélection de variables

Toutes nos variables sont potentiellement explicatives, trouvons celles qui interviennent réellement dans l'explication de $T$.

Commençons par regarder les facteurs d'inflation de la variance (VIF), pour vérifier si nos variables explicatives ne sont pas trop corrélées entre elles.

```{r vif}
vif(mod1)
```

Tout nos VIFS sont acceptables (inférieurs à 3). 

Pour faire notre sélection parmi les variables restantes, nous allons utiliser une procédure de modèle emboîté. Comme notre modèle contient la constante, nous pouvons nous intéresser à la maximisation de $R^2_a$ et au critère BIC (Bayesian Information Criterion).
 
Commençons par un modèle avec nos 5 variables explicatives.

```{r choix-modèle1, fig.width = 10, out.width = "80%"}
choix1 <- regsubsets(Téléphones~ Densité.population + PIB + Agriculture + Taux.de.natalité , data = df.countries.scale, nvmax = 5, really.big = T)
par(mfrow = c(1, 2))
plot(choix1, sclae="bic")
plot(choix1, scale="adjr2")
```

Nous supprimons alors les variables Densité et Agriculture.

```{r mod2}
mod2 <- lm(Téléphones ~ PIB + Services + Taux.de.natalité, data = df.countries.scale)
```

On itère le procédé avec nos 3 variables explicatives restantes.

```{r choix-modèle2, fig.width = 10, out.width = "80%"}
choix2 <- regsubsets(Téléphones~ PIB + Services + Taux.de.natalité , data = df.countries.scale, nvmax=3, really.big=T)
par(mfrow = c(1, 2))
plot(choix2, scale="bic")
plot(choix2, scale="adjr2")
```

Nous gardons l'ensemble des variables restantes, c'est à dire le PIB, les Services et le Taux de natalité.

```{r modèle-choisi}
mod_choisi <- mod2
summary(mod_choisi)
```

Finalement, après l'étape de sélection, notre modèle linéaire s'écrit :

<h4 style="text-align: center; border-style:solid; border-color:#FF0000; padding: 1em;">

Téléphones = `r round(mod_choisi$coefficients['PIB'],2)` PIB + `r round(mod_choisi$coefficients['Services'],2)` Services - `r abs(round(mod_choisi$coefficients['Taux.de.natalité'],2))` Taux de natalité + $\varepsilon$

</h4>

Avec $\varepsilon$ une variable aléatoire centrée.

<br>

### D - Validation du modèle

Nous allons vérifier à nouveau que nous n'avons pas de valeurs problématiques en regardant les valeurs aberrantes, les points leviers et les distances de Cook.

```{r residus-student3, fig.width = 11, out.width = "100%"}
df.residus <- data.frame(residu = rstudent(mod_choisi))
n <- length(df.countries.scale$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
# n-p-1=203 >30 donc OK de prendre 2
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupes <- rep("Valeur non aberrante", n)
df.residus[ID_suspect, ]$Groupes <- "Valeur aberrante"

plot_rstudent <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupes) + geom_point()
plot_rstudent <- plot_rstudent + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent <- plot_rstudent + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes") + theme(plot.title = element_text(hjust = 0.5))

nb_aberrant2 <- sum(abs(df.residus$residu) > 2)

# Points leviers
p <- mod_choisi$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod_choisi))
ID_levier <- (1:n)[df.H$H > seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupes <- rep("Point non levier", n)
df.H[ID_levier, ]$Groupes <- "Point levier"

plot_levier <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupes) + geom_point()
plot_levier <- plot_levier + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier <- plot_levier + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier <- plot_levier + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier <- plot_levier + xlab('Index') + ylab('hii') + labs(title="Analyse des points levier") + theme(plot.title = element_text(hjust = 0.5))


nb_leviers2 <- sum(df.H$H>seuil2)

df.cook <- data.frame(cook = cooks.distance(mod_choisi))
s1 <- qf(0.1, p, n-p)
s2 <- qf(0.5, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 3)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 2)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analyse des distances de Cook") + theme(plot.title = element_text(hjust = 0.5))


l<- which.max(cooks.distance(mod_choisi))

grid.arrange(plot_rstudent, plot_levier, widths = c(1/2, 1/2))
plot_cook
```

On a `r nb_aberrant2` valeurs aberrantes dans un échantillon de taille `r dim(df.countries)[1]` donc `r round(nb_aberrant2*100/dim(df.countries)[1],2) `% des résidus studentisés $t_i^*$ ne se trouvent pas dans l'intervalle [−2,2]. C'est une proportion acceptable, car inférieure à 5%. Il y a `r nb_leviers2` points leviers qui dépassent le deuxième seuil. Nous avons moins de points leviers et de valeurs aberrantes que dans le modèle global. 

Comme précédemment, l'observation 115, qui est le Luxembourg, est une observation aberrante et un point levier. Mais dans ce modèle, le Luxembourg a  une distance de Cook qui dépasse le seuil préoccupant (`r round(s2,2)`). Regardons cette observation de plus près :

```{r le-luxembourg}
df.countries[c("Switzerland", 'Luxembourg', 'France', 'Belgium'), c(1, 2, 5, 7, 8)]
sortedPIB <- sort(df.countries$PIB, decreasing = TRUE)
```

On remarque en effet que le Luxembourg est le pays au PIB le plus élevé de notre dataset : `r sortedPIB[1]`. Les deux prochains PIB valent `r sortedPIB[2]` et `r sortedPIB[3]`. Nous décidons donc de supprimer cette observation et de réaliser une nouvelle régression linéaire.

```{r sans-le-Luxembourg}
nouvcountries <- df.countries.scale[c(-115), ]
mod_affiné <- lm(Téléphones ~  PIB + Services + Taux.de.natalité, data = nouvcountries)
summary(mod_affiné)
```

Ainsi, après la sélection de variable et l'étude des observations, on en déduit que notre modèle linéaire s'écrit :

<h4 style="text-align: center; border-style:solid; border-color:#FF0000; padding: 1em;">
Téléphones = `r round(mod_affiné$coefficients['PIB'],2)` PIB + `r round(mod_affiné$coefficients['Services'],2)` Services - `r abs(round(mod_affiné$coefficients['Taux.de.natalité'],2))` Taux de natalité + $\varepsilon$
</h4>


Nous avons centré et réduit nos observations donc nos coefficients $\beta_j$ sont comparables. Dans notre modèle linéaire, c'est le PIB du pays qui influence le plus $T$. La part de la population dans les services influence également positivement $T$, même si cette influence est moins importante. Finalement, le taux de natalité du pays influence également $T$ mais cette fois-ci négativement.

Notons que les coefficients diffèrent des coefficients précédents lorsqu'on avait gardé le Luxembourg, notamment le coefficient devant le PIB et celui devant le taux de natalité. 

À présent, nous allons réaliser une analyse de la normalité des résidus, pour vérifier si notre modèle linéaire est bien Gaussien. Traçons un QQ-plot qui compare les quantiles empiriques associés aux studentisés ($t_1^*,...,t_n^*$) aux quantiles de la loi de Student $\mathcal{T}(n-p-1)$ , ou n=207 et p=4, pour valider l'hypothèse de la normalité des résidus.

```{r qqplot-residus}
n <- length(nouvcountries$Téléphones)
p <- mod_affiné$rank
df.residus2 <- data.frame(residu = rstudent(mod_affiné))

quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs = sort(df.residus2$residu), Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)") + labs(title="QQ-plot quantiles des studentisés contre quantiles théoriques") + theme(plot.title = element_text(hjust = 0.5))
qq.plot
```

Le QQ-plot des résidus studentisés contre les quantiles d'une loi de Student de degrés de liberté n-p-1 =`r n-p-1` semble raisonnable.
Nous validons l'hypothèse de la normalité des résidus. Notre modèle linéaire est Gaussien.


On peut conclure que le nombre de téléphones pour mille habitants est lié linéairement à des caractéristiques préalablement existantes. Ce n'est donc pas un critère de développement qui bouscule les classifications déjà établies. 
 
Terminons cette partie avec une cross-validation, en découpant aléatoirement notre jeu de données en 80/20 :

```{r découpage-prediction}
idx = sample(1:208, 166)
df.countries.app <- df.countries.scale[idx,]
df.countries.test <- df.countries.scale[-idx,]

n_test <- length(df.countries.test$Téléphones)
mod_prediction <- lm(Téléphones ~  PIB + Services + Taux.de.natalité, data = df.countries.app)
prediction <- predict.lm(mod_prediction, newdata = df.countries.test)
summary_prediction <- summary(prediction)
mod_prediction
```

Comparons avec les valeurs réelles en utilisant l'écart en valeur absolue (EVA) et l'écart quadratique moyen (EQM) :

```{r EVA-EQM}
EQM <- sum((prediction- df.countries.test$Téléphones)^2)/n_test
EVA <- sum(abs(prediction- df.countries.test$Téléphones))/n_test
var_test <- var(df.countries.test$Téléphones)
rapport_variations <- EQM/var_test
```

L'écart en valeur absolue vaut `r round(EVA, 2)` et l'écart quadratique moyen `r round(EQM, 2)`. Étant donné que l'EVA > l'EQM, les déviations sont en moyenne inférieures à 1, car l'EQM est plus sensible aux écarts supérieurs à 1. De plus, l'échantillon de test a pour moyenne `r round(summary(df.countries.test$Téléphones)['Mean'], 2)` et pour variance `r round(var_test, 2)`. On observe que EQM/var(Téléphones) = `r round(rapport_variations, 2)`, donc notre prédiction ne disperse pas beaucoup plus les données autour des valeurs réelles que la variance de l'échantillon ne les disperse.  

Vérifions que les prédictions restent dans de bons intervalles de confiance :

```{r plot-IC-predict}
prediction <- predict(mod_prediction, newdata = df.countries.test, interval = "confidence")
df.ic <- as.data.frame(cbind(pays = df.countries.test$Pays, tel = df.countries.test$Téléphones, prediction))
rownames(df.ic) <- NULL
ggplot(df.ic, aes(x = pays, y = fit)) + geom_point(size = 4) + geom_errorbar(aes(ymax = upr, ymin = lwr)) + xlab("Pays") + ylab("Prédictions") + theme(axis.text.x = element_blank(), axis.text.y = element_blank())
```

On voit que la plupart des valeurs tombent dans leurs intervalles de confiance. Cependant, il arrive que certaines valeurs soient hors des intervalles (selon le tirage aléatoire des 80/20). Peut-être manque-t-il des variables dans notre modèle?

<br>

## III - Importance de la Région d'appartenance

### A - ANOVA

La partie précédente nous a montré qu'un modèle linéaire explique relativement bien $T$. 
Dans cette partie, nous voudrions savoir si la région d'appartenance du pays a une influence significative sur $T$. 
La variable $T$ engendre-t-elle la distinction traditionnelle Nord-Sud? 


Nous avons observé dans l'analyse bivariée que la région d'appartenance du pays influe sur $T$ (cf. Boxplot par région). Nous allons ici voir dans quelle mesure cette influence a lieu. 

Regardons notre variable Région.

```{r variable-région}
table(df.countries$Région)
```
La variable Région possède 11 niveaux avec des tailles différentes. Notre plan d'expérience est complet, répété et n'est pas équilibré en chaque variable. 

Commençons par estimer les paramètres de notre modèle linéaire.  

```{r summary-complet}
complet <- lm(Téléphones ~ Région, data = df.countries)
summary_complet <- summary(complet)
summary_complet
```


Dans ce modèle, notre niveau de référence est la région Asie. Pour le modèle complet, le $R^2$ égal à `r round(summary_complet$r.squared, 2)`, qui est relativement éloigné de 1. La p-valeur du test global de Fisher indique que le modèle explique mieux la réalité que le modèle contenant uniquement la constante.

Analysons maintenant la variance grâce à une ANOVA sur notre modèle.

```{r anova}
anov <- anova(complet)
anov
```

La p-valeur associée à la variable région est de l'ordre de $\ 10^{-16}$. Il n'y a pas de doute : la région influence $T$. 


### B - Analyse des résidus

Commençons par regarder si nous avons des valeurs aberrantes et des points leviers. 

```{r residus-student, fig.width = 11, out.width = "100%"}
df.residus <- data.frame(pays = df.countries$Pays, residu = rstudent(complet))
n <- length(df.countries$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
ID_suspect <- ID_suspect[!is.na(ID_suspect)]
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupe <- rep("Non aberrante", n)
df.residus[ID_suspect, ]$Groupe <- "Aberrante"

plot_rstudent2 <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupe) + geom_point()
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent2 <- plot_rstudent2 + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes, ANOVA") + theme(plot.title = element_text(hjust = 0.5))


nb_aberrant3 <- sum(abs(df.residus$residu) > 2)

p <- complet$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(complet))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupe <- rep("Non levier", n)
df.H[ID_levier, ]$Groupe <- "Levier"

plot_levier2 <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupe) + geom_point()
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier2 <- plot_levier2 + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier2 <- plot_levier2 + xlab('Index') + ylab('hii') + labs(title="Analayse des points levier, ANOVA") + theme(plot.title = element_text(hjust = 0.5))


grid.arrange(plot_rstudent2, plot_levier2, widths = c(1/2, 1/2))

nb_leviers3 <- sum(abs(hatvalues(complet) > seuil2))
```

Nous avons `r nb_aberrant3` valeurs aberrantes, soit `r round((nb_aberrant3/n)*100,2)` % de nos observations ne sont pas dans l'intervalle [-2;2] ce qui est acceptable (moins de 5%). Nous avons `r nb_leviers3` points leviers.  Analysons à présent les distances de Cook. 
 
```{r df-cook-anov}
df.cook <- data.frame(cook = cooks.distance(complet))
s1 <- qf(0.5, p, n-p)
s2 <- qf(0.1, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 2)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 3)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analayse des distances de Cook, ANOVA") + theme(plot.title = element_text(hjust = 0.5))
plot_cook
```

Aucune distance de Cook ne dépasse le premier seuil et à fortiori le deuxième. Nous pouvons donc garder toutes nos observations. 
 
Finalisons cette analyse en vérifiant l'hypothèse de normalité des résidus. 
 
```{r normalité-résidus}
quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs = df.residus$residu[order(df.residus$residu)], Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)") + labs(title="QQ-plot quantiles des résidus studentisés contre quantiles théoriques, ANOVA") + theme(plot.title = element_text(hjust = 0.5))
qq.plot
```

On peut valider l'hypothèse selon laquelle les résidus sont gaussiens, même si l'adéquation est moins nette que précédemment. 


Pour conclure, la région du pays d'appartenance joue un rôle quant au nombre de téléphones pour mille habitants. Les coefficients pour l'Amérique du Nord et l'Europe de l'Ouest se détachent positivement. Inversement, ce sont les pays d'Afrique subsaharienne qui ont les taux le plus bas, suivis par les pays d'Afrique du Nord.  
<br>



### C - La fracture Nord-Sud

Dans notre régression précédente, nous avions certaines modalités avec une p-valeur associée suffisamment faible pour avoir des coefficients significatifs. Ce n'était pas le cas pour d'autres, notamment pour la région Baltique, l'Afrique du Nord ou l'Océanie. La région Baltique contient les données de seulement 3 pays et l'Afrique du Nord de 5. Pour palier cette problématique, nous décidons de regrouper les régions ensembles, suivant qu'elles sont dites du Nord ou du Sud.

Nous créons donc deux nouveaux sous-groupes :

-   La région du Nord : l'Amérique du Nord et l'Europe de l'Ouest.

-   La région du Sud : les 9 autres régions, soit l'ex-URSS, l'Amérique latine et caribéenne, l'Europe de l'Est, les Baltiques le proche orient, l'Afrique du Nord, l'Océanie, l'Asie et l'Afrique subsaharienne.


```{r nord-et-sud}
idx_nord_a <- df.countries$Région == 'NORTHERN AMERICA                   '
idx_nord_e <- df.countries$Région == 'WESTERN EUROPE                     '
df.nordsud <- data.frame(df.countries)
df.nordsud$Région <- "SUD"
df.nordsud$Région[idx_nord_a] <- "NORD"
df.nordsud$Région[idx_nord_e] <- "NORD"

nordsud <- lm(Téléphones ~ Région, data = df.nordsud)
summary_nordsud <- summary(nordsud)
summary_nordsud

boxplot_nordsud <- ggplot(data = df.nordsud) + aes(x = as.factor(Région), y = Téléphones) + geom_boxplot() + xlab("Nord et sud")
boxplot_nordsud
```

Ici, nous créons clairement 2 modalités pour notre variable Région, bien séparées par leurs 1er et 3ème quartiles, ce qui nous est confirmé par l'ANOVA :

```{r anova-nordsud}
anova_nordsud <- anova(nordsud)
anova_nordsud
```

On conclut cette partie en effectuant une analyse des résidus. 

```{r residus-student4, fig.width = 11, out.width = "100%"}
df.residus <- data.frame(région = df.nordsud, residu = rstudent(nordsud))
n <- length(df.nordsud$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
ID_suspect <- ID_suspect[!is.na(ID_suspect)]
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupe <- rep("Non aberrante", n)
df.residus[ID_suspect, ]$Groupe <- "Aberrante"

plot_rstudent2 <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupe) + geom_point()
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent2 <- plot_rstudent2 + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes, ANOVA Nord-Sud") + theme(plot.title = element_text(hjust = 0.5))


nb_aberrant4 <- sum(abs(df.residus$residu) > 2)

p <- nordsud$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(nordsud))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupe <- rep("Non levier", n)
df.H[ID_levier, ]$Groupe <- "Levier"

plot_levier2 <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupe) + geom_point()
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier2 <- plot_levier2 + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier2 <- plot_levier2 + xlab('Index') + ylab('hii') + labs(title="Analayse des points levier, ANOVA Nord-Sud") + theme(plot.title = element_text(hjust = 0.5))


grid.arrange(plot_rstudent2, plot_levier2, widths = c(1/2, 1/2))

nb_leviers4 <- sum(abs(hatvalues(complet) > seuil2))
```

On a `r nb_aberrant4` valeurs aberrantes et `r nb_leviers4` points leviers, soit la moitié de nos observations. 
 
```{r df-cook-anov-nordsud}
df.cook <- data.frame(cook = cooks.distance(nordsud))
s1 <- qf(0.5, p, n-p)
s2 <- qf(0.1, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 2)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 3)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analayse des distances de Cook, ANOVA Nord-Sud") + theme(plot.title = element_text(hjust = 0.5))
plot_cook
```
Aucune observation ne dépasse le premier seuil ou le deuxième. Nous gardons toutes nos observations. 
 

```{r normalité-résidus-nordsud, out.width = "70%"}
quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs=df.residus$residu[order(df.residus$residu)], Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)") + labs(title="QQ-plot quantiles résidus studentisés contre quantiles théoriques, ANOVA Nord-Sud") + theme(plot.title = element_text(hjust = 0.5))
qq.plot
```
On a du mal à croire à des résidus gaussiens ici. Un autre type de modélisation serait à envisager.
 

## Conclusion

  Au fil de cette analyse, nous nous sommes rendu compte que le nombre de téléphones pour mille habitants est corrélé aux indicateurs dits classiques de développement. En effet, en 2000, le PIB, le taux de natalité et la part de la population dans les services suffisaient à prédire correctement cette variable. De plus, ce critère de développement crée la même fracture Nord-Sud observable avec les autres critères de développement. Ainsi, notre variable d’intérêt n'ajoute pas d'information suffisamment pertinente lors d'une analyse de développement d'un pays.


  Quand serait-il aujourd'hui? Le nombre de téléphones pour mille habitants a explosé dans tous les pays. En France, 54 millions de personnes en 2020 possédaient un smartphone (chiffre de l'Arcep, l'Autorité de régulation des communications électroniques) pour 67 millions d'habitants (chiffre de l'INSEE). On a donc un taux de 800 téléphones pour mille habitants. Nous n'étions qu'à 586 en 2008. Cette explosion n'a pas eu lieu que dans les pays dits développés. Les smartphones ont pénétré les marchés émergents au point d'avoisiner des taux rencontrés dans les pays développés. Pourtant, les critères comme le PIB et le taux de natalité ne se sont pas harmonisés au niveau mondial. 


  L'explication linéaire du nombre de téléphones pour mille habitants par les critères de développement serait-elle encore pertinente aujourd'hui?



<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>


## Annexe

### Analyse univariéé, adéquation à une loi

Au vu de l'histogramme de $T$, nous pouvions penser que $T$ est un échantillon de loi exponentielle, c'est-à-dire que $T$ est la réalisation d'une variable aléatoire  $X$ suivant une loi exponentielle de paramètre $\lambda$. La méthode des moments nous propose la moyenne empirique de $T$ comme estimateur sans biais, consistant et asymptotiquement normal de l'espérance.

La moyenne empirique de $T$ est $\mu =$ `r round(mu)`. En prenant $\hat \lambda =$ `r round(1/round(mu),3)`, nous voulons vérifier que notre hypothèse est acceptable. Nous allons alors tracer le QQ-plot entre les quantiles théoriques de $X$  et les quantiles empiriques de $T$. 


```{r T-exponentielle, fig.height = 6, fig.width = 8, out.width = "70%"}

df.qq <- data.frame(df.countries$Téléphones)
names(df.qq) <- "Téléphones"
df.qq$Téléphones <- df.qq$Téléphones/mu
qqplot <- ggplot(data = df.qq, aes(sample = Téléphones)) + stat_qq(distribution = stats::qexp)
qqplot <- qqplot + geom_abline(intercept = 0,slope = 1, col = "blue") + labs(title="Diagramme quantile-quantile") + xlab("Quantiles théoriques") + ylab("Quantiles observés") + theme(plot.title = element_text(hjust = 0.5))

qqplot

```

Les points de notre QQ-plot s'alignent bien sur la première bissectrice. C'est encourageant. L'adéquation n'est pas parfaite mais elle est suffisamment raisonnable pour retenir l'hypothèse que $T$ suit une loi exponentielle de paramètre $\hat \lambda$. 

Nous allons réaliser un test de Kolmogorov-Smirnov sur notre échantillon, puisque la variable Téléphones et la loi exponentielle sont toutes deux de lois continues. 
   
```{r test-T}
rexpsample <- df.countries$Téléphones/mu
kstest <- ks.test(df.countries$Téléphones, rexpsample)
kstest
p <- kstest$p.value
```

Notre p-valeur est inférieure à 2.2e-16 donc on rejette $H_0$ au profit de l'hypothèse alternative $H_1$ sans hésitation. On peut conclure que notre variable $T$ ne suit pas une loi exponentielle de paramètre $\hat\lambda$. $T$ est la réalisation d'une autre loi, dont on ne connait pas la nature exacte.



