---
title: "Mais qui as-des téléphones ?!"
author: "Justine Blanchot et Elyass Sayd, Groupe 0"
date: "13/02/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(comment = NA)
```
```{css, echo=FALSE}
h1, h2 {
  text-align: center;
}
```


### Introduction

Avant la fameuse conférence *Apple Keynote* de 2007 par Steve Jobs où il annonçait la sortie du premier iPhone, personne n'aurait pu imaginer que les écrans tactiles se retrouveraient dans toutes les mains. L'iPhone était le précurseur du marché des smartphones qui a connu une des expansions les plus fulgurantes avec l'amélioration constante des infrastructures internet. Aurions-nous pu prévoir quels marchés allaient-être les plus réceptifs à l'arrivée de cette technologie? À l'aide de quels critères? Nous allons au fil de ce rapport nous questionner sur les corrélations possibles pour un pays donné entre le nombre de téléphones pour mille habitants et différents critères de développement. 


### Problématique et objectif

A partir d'un jeu de données issu de Kaggle, publié en 2017 par Fernando Lasso, intitulé "Countries of the world" et rassemblant des données du gouvernement américain (Anciennes données du CIA World Factbook et International Consortium for the Advancement of Academic Publication  https://gsociology.icaap.org/dataupload.html), nous allons essayer d'expliquer la déjà existante fougue du téléphone mobile en 2000 en fonction de certains indicateurs. 
Si le temps nous le permets, nous comparerons notre analyse avec une tendance plus récente, à l'aide de nouvelles données du World Factbook.

Nous tenterons donc de répondre à la problématique suivante:

#### **Aurions-nous pu anticiper la réussite du marché des téléphones portables dans un pays à l'aide des indicateurs classiques de développement? Si oui, à l'aide desquels? **


### I - Analyse descriptive des données

#### A - Analyse du jeu de données

Le jeu de données que nous avons choisi contient les données de 227 pays par rapport à 19 variables. Dans le cadre de cette étude, nous nous limiterons aux variables suivantes: la région d'appartenance du pays, la densité de population (nombre habitants par miles carré), le PIB par habitant et enfin la part de la population active travaillant dans l'agriculture, l’industrie et les services.

Pour être en adéquation avec les consignes du projet, nous avons vérifié que nous avions bien plus de 100 données (227 dans notre cas), et nous avons choisi 6 variables d’intérêt, parce qu’il était recommandé d’en prendre 3 ou 4 minimum. Nous avons également renommé les noms des colonnes du fichier en français. On remarque également que notre variable d’intérêt possède 4 valeurs manquantes, nous décidons de les retirer.
  

```{r}
library("ggplot2")
library("ggThemeAssist")
library("gridExtra")
df.original <- read.csv("countries.csv", dec=",")
df.countries <- df.original[, c("Pays", "Téléphones", "Région", "Densité.population", "PIB", "Agriculture", "Industrie", "Services")]
rownames(df.countries) <- df.countries$Pays
vec_retirer = is.na(df.countries)
idx = apply(vec_retirer, 1, sum) == 0
df.countries <- df.countries[idx, ]
```

#### B - Analyse univariée de la variable d'intérêt

Introduisons des notations:
$T$, pour téléphones, est la variables à expliquer, c'est-à-dire le nombres de téléphones pour mille habitants. 
  
$T$ est la réalisation d'une variable aléatoire $X$. Dans cette première partie, nous allons analyser les données de $T$ et essayer de déterminer la loi de $X$. Profitons-en pour afficher quelques caractéristiques de $T$:

```{r}
sommaire <- summary(df.countries$Téléphones)
mu = sommaire["Mean"]
sommaire
```

Avant toutes recherches plus précises sur notre variable, nous allons nous convaincre qu'elle est continue. Pour ce faire, traçons sa fonction de répartition empirique. 

```{r}
fdrplot <- ggplot(df.countries, aes(Téléphones)) + stat_ecdf(geom="step") + labs(title="Fonction de répartition empirique de T" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("")
long <- length(unique(df.countries$Téléphones))
fdrplot
```
    
On voit que la fonction de répartition empirique réalise beaucoup de sauts. Elle en réalise exactement `r long`. `r long` est "grand" devant 247 donc notre variable d’intérêt est continue. 
  
Nous pouvons alors tracer son histogramme. 
  
```{r}
hist1 <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 20)
hist1 <- hist1 + labs(title="Histogramme de T", subtitle = "2O sous-intervalles de [0,1000]") + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))

hist2 <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 10)
hist2 <- hist2 + labs(title="Histogramme de T", subtitles=" 10 sous-intervalles de [0,1000]" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))

grid.arrange(hist1, hist2)
```
  
  Les histogrammes sont unimodaux avec un pic dans en 0, puis décroissant. On en déduit que dans notre jeu de données, beaucoup de pays ont moins de 100 téléphones pour mille habitants et à l'inverse, peu de pays on plus de de 700 téléphones pour mille habitants. 
  
  Au vue de ces histogrammes, nous pouvons penser que $T$ est un échantillon de loi exponentielle, c'est-à-dire  $X$ suit une loi exponentielle de paramètre $\lambda$. L'espérance d'une loi exponentielle est $\frac{1}{\lambda}$. La méthode des moments nous propose la moyenne empirique de $T$ comme estimateur sans biais, consistant et asymptotiquement normal de l'espérance. 
  

Nous avons vu dans le sommaire plus haut que la moyenne empirique de $T$ est $\hat \mu =$ `r mu`. En prenant $\hat \lambda = \frac{1}{236.1} = 4.24 \cdot 10^{-3}$, nous voulons vérifier que notre hypothèse est acceptable. Nous allons alors tracer:
   
1.  L'histogramme de $T$ et la densité $\hat \lambda e^{\hat \lambda x}$

2.  La fonction de répartition empirique de $T$ et sa fonction de répartition de $\hat \lambda e^{\hat \lambda x}$ .

3.  Le QQ-plot de entre les réalisation théoriques et empiriques de $T$.

4.  Quelques boxplot pour voir la répartition des données par zone géographique.

```{r}
lambda = 1/mu
hist <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 8, aes(y = stat(density)))
hist <- hist + labs(title="Histogramme de T" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("")
hist <- hist + stat_function(fun = function(x) {dexp(x, rate = lambda)}, col = 'blue')

fdrplot <- ggplot(df.countries, aes(Téléphones)) + stat_ecdf(geom="step") + labs(title="Fonction de répartition empirique de T" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("")
fdrplot <- fdrplot + stat_function(fun = function(x) {pexp(x, rate = lambda)}, col = 'blue')

cdfexp <- function(x, rate) {
  return(1-exp(rate*x))
}

df.qq <- data.frame(df.countries$Téléphones)
names(df.qq) <- "Téléphones"
df.qq$Téléphones <- df.qq$Téléphones/mu
qqplot <- ggplot(data = df.qq, aes(sample = Téléphones)) + stat_qq(distribution = stats::qexp)
qqplot <- qqplot + geom_abline(intercept = 0,slope = 1, col = "blue")

boxplot1 <- ggplot(data=df.countries) + aes(x=as.factor(Région), y=Téléphones) + scale_x_discrete(guide = guide_axis(n.dodge=4)) + geom_boxplot()
boxplot2 <- ggplot(data=df.countries) + aes(y=Téléphones) + geom_boxplot()

grid.arrange(hist, fdrplot, qqplot, boxplot2)
boxplot1

```

L'adéquation n'est pas parfaite mais elle est suffisament raisonnable pour restenir l'hypothèse qu'il s'agit d'une loi exponentielle. 
   
```{r}
rexpsample <- rexp(length(df.countries$Téléphones), rate = lambda)
ks.test(df.countries$Téléphones, rexpsample)
```

### II - Analyse bi-variée  

#### A - Régression linéaire multiple

Dans cette partie, nous allons nous intéresser à une régression linéaire permettant d'exprimer le nombre de téléphone pour mille habitants parla densité de population (nombre habitants par miles carré), le PIB par habitant et enfin la part de la population active travaillant dans l'agriculture, l’industrie et les services.

On considère le modèle linéaire suivant:

$$\text{Téléphones} = \beta_0 + \beta_1\text{PIB} + \beta_2\text{Densité}+\beta_3\text{Agriculture}+\beta_4\text{Industrie}\ + \beta_5\text{Services} + \varepsilon.$$
Commençons par centrer et réduire les données pour qu'elles soient à la même échelle. Puis, réalisons une première régression linéaire. 
```{r}
mod1 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Industrie + Services, data = df.countries)
summary(mod1)
```
Avant d'aller plus loin dans la régression linéaire et la sélection de variables nous allons nous intéresser à notre jeu de données, voir s'il comporte des valeurs aberrantes, des points leviers et analyser les distances de Cook. 

1) Valeurs aberrantes

```{r}
df.residus <- data.frame(residu = rstudent(mod1))
n <- length(df.countries$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
df.residus$ID <- rep("",n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$group <- rep("Non aberrante",n)
df.residus[ID_suspect,]$group <- "Aberrante"

plot2 <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=group) + geom_point()
plot2 <- plot2 + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot2 <- plot2 + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot2 <- plot2 + geom_text(aes(label=ID),hjust=0, vjust=0)
plot2 <- plot2 + xlab('Index') + ylab('Résidus studentisés')
plot2
```
On a 10 valeurs aberrantes dan un échantillon de taille 209. 

2) QQ-plot

```{r}
#QQ-plot residus et studentisés

n <- length(df.countries$Téléphones)
p <- mod1$rank

quant.t <- qt((1:n)/n,n-p-1)

df_qq <- data.frame(Obs = sort(df.residus$residu), Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 1, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Student T(n-p-1)")
qq.plot <- qq.plot + xlim(-5,5) + ylim(-5,10)
qq.plot
```

###### 3) Points levier

```{r}
# Points leviers
p <- mod1$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod1))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("",n)
df.H[ID_levier,]$ID <- ID_levier
df.H$group <- rep("Non levier",n)
df.H[ID_levier,]$group <- "Levier"

plot6 <- ggplot(data = df.H) + aes(x=1:n, y = H, color=group) + geom_point()
plot6 <- plot6 + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot6 <- plot6 + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot6 <- plot6 + geom_text(aes(label=ID),hjust=0, vjust=0)
plot6 <- plot6 + xlab('Index') + ylab('hii')
plot6
```
Il y a 7 valeurs qui dépassent les deux seuils. 

##### 4) Distance de Cook

```{r}
# Distance de cook
df.cook <- data.frame(cook = cooks.distance(mod1))
s1 <- qf(0.5,p,n-p)
s2 <- qf(0.1,p,n-p)
plot4 <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot4 <- plot4 + geom_hline(yintercept = s1, col = "blue", linetype = 2)
plot4 <- plot4 + geom_hline(yintercept = s2, col = "blue", linetype = 3)
plot4 <- plot4 + xlab('Index') + ylab('Distance de Cook')
plot4

```

On observe qu'une valeur dépasse le seuil préoccupant du quantile $F_{n,n-p}^{-1}(0.5)$. 
 
```{r}
max(hatvalues(mod1))

max(cooks.distance(mod1))
which.max(cooks.distance(mod1))
```


```{r}
nouvcountries<-df.countries[-19,]
mod2 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Industrie + Services, data = nouvcountries)

```

```{r}
df.residus <- data.frame(residu = rstudent(mod2))
n <- length(nouvcountries$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu)>2]
df.residus$ID <- rep("",n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$group <- rep("Non aberrante",n)
df.residus[ID_suspect,]$group <- "Aberrante"

plot2 <- ggplot(data = df.residus) + aes(x=1:n, y = residu, color=group) + geom_point()
plot2 <- plot2 + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot2 <- plot2 + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot2 <- plot2 + geom_text(aes(label=ID),hjust=0, vjust=0)
plot2 <- plot2 + xlab('Index') + ylab('Résidus studentisés')
plot2
```

```{r}
df.cook <- data.frame(cook = cooks.distance(mod2))
s1 <- qf(0.5,p,n-p)
s2 <- qf(0.1,p,n-p)
plot4 <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot4 <- plot4 + geom_hline(yintercept = s1, col = "blue", linetype = 2)
plot4 <- plot4 + geom_hline(yintercept = s2, col = "blue", linetype = 3)
plot4 <- plot4 + xlab('Index') + ylab('Distance de Cook')
plot4
```

```{r}
p <- mod2$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod2))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("",n)
df.H[ID_levier,]$ID <- ID_levier
df.H$group <- rep("Non levier",n)
df.H[ID_levier,]$group <- "Levier"

plot6 <- ggplot(data = df.H) + aes(x=1:n, y = H, color=group) + geom_point()
plot6 <- plot6 + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot6 <- plot6 + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot6 <- plot6 + geom_text(aes(label=ID),hjust=0, vjust=0)
plot6 <- plot6 + xlab('Index') + ylab('hii')
plot6
```

