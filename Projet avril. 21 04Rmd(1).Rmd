---
title: "Mais qui a des téléphones ?!"
author: "Justine Blanchot et Elyass Sayd, Groupe 0"
date: "25/04/2022"
output:
  html_document:
#    css: bootstrap.min.css
#  bookdown::pdf_document2:
#    template: latex_template.tex
#  pdf_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment=NA, echo=FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.align = "center")
```
```{css layout, echo = FALSE}
h1, h2 {
  text-align: center;
}
```

### <br><br> Introduction

<p style="text-indent: 20px"> Avant la fameuse conférence *Apple Keynote* de 2007 par Steve Jobs où il annonçait la sortie du premier iPhone, personne n'aurait pu imaginer que les écrans tactiles se retrouveraient dans toutes les mains. L'iPhone était le précurseur du marché des smartphones, marché qui a connu une des expansions les plus fulgurantes du XXe siècle, avec l'amélioration constante des infrastructures internet. Aurions-nous pu prévoir quels marchés allaient-être les plus réceptifs à l'arrivée de cette technologie? À l'aide de quels critères? Nous allons au fil de ce rapport nous questionner sur les corrélations possibles pour un pays donné entre le nombre de téléphones pour mille habitants et différents critères classiques pour mesurer le développement d'un pays. </p>



### Problématique et objectif

 <p style="text-indent: 20px"> A partir d'un jeu de données issu de Kaggle, publié en 2017 par Fernando Lasso, intitulé "Countries of the world" et rassemblant des données du gouvernement américain (anciennes données du CIA World Factbook et International Consortium for the Advancement of Academic Publication  https://gsociology.icaap.org/dataupload.html), nous allons essayer d'expliquer l'engouement autour du téléphone mobile en 2000 en fonction de certains indicateurs. </p> 

<p style="text-indent: 20px">Nous tenterons donc de répondre à la problématique suivante: </p>

<br> <p style="text-indent: 20px"> **Aurions-nous pu anticiper la réussite du marché des téléphones portables dans un pays à l'aide des indicateurs classiques de développement? Si oui, à l'aide desquels? ** </p>


#### <br> Sommaire:

<p style="text-indent: 20px"> I - Analyse descriptive des données</p>
<p style="text-indent: 40px">A - Analyse du jeu de données</p>
<p style="text-indent: 40px">B - Analyse univariée de la variable d'intérêt</p>
<p style="text-indent: 40px">C - Analyse bi-variée</p>

<p style="text-indent: 20px"> II - Régression linéaire multiple</p>
<p style="text-indent: 40px">A - Introduction </p>
<p style="text-indent: 40px">B - Sélection de variable</p>
<p style="text-indent: 40px">C - Validation du modèle</p>


<p style="text-indent: 20px"> III - Modélisation linéaire avec variable qualitative, réalisation d'une ANOVA.</p> 
<p style="text-indent: 40px">A - Apprentissage du modèle </p>
<p style="text-indent: 40px">B - Test du modèle</p>

###  I - Analyse descriptive des données

#### <br> A - Analyse du jeu de données

<br><p style="text-indent: 20px">Le jeu de données que nous avons choisi contient les données de 227 pays par rapport à 19 variables. Dans le cadre de cette étude, nous nous limiterons aux variables suivantes: la région d'appartenance du pays, la densité de population (nombre d'habitants par miles carré), le PIB par habitant, le taux de natalité et, enfin, la part de la population active travaillant dans l'agriculture, l’industrie et les services. Parmi ces sept variables, nous avons six quantitatives et une qualitative (la région d'appartenance).</p>

<br><p style="text-indent: 20px"> Par définition, les variables Service, Industrie et Agriculture forment une partition de la population active dans le pays.Nous décidons alors de retirer de notre étude, sans perte de précision, la variable Industrie. 

```{r import-nettoyage-données}
library("ggplot2")
library("ggThemeAssist")
library("gridExtra")
library("GGally")
library("car")
library("leaps")
df.original <- read.csv("countries.csv", dec=",", encoding="UTF-8")
df.countries <- df.original[, c("Pays", "Téléphones", "Région", "Densité.population", "PIB", "Agriculture", "Services", "Taux.de.natalité")]
rownames(df.countries) <- df.countries$Pays
vec_retirer = is.na(df.countries)
idx = apply(vec_retirer, 1, sum) == 0
df.countries <- df.countries[idx, ]
```
 

#### <br> B - Analyse univariée de la variable d'intérêt


<p style="text-indent: 20px"> Introduisons des notations: </p>

$T$, pour "téléphones", est la variables à expliquer, c'est-à-dire le nombres de téléphones pour mille habitants. 
Dans cette première partie, nous allons analyser les données de $T$.</p>
<br><p style="text-indent: 20px">Commençons par regarder quelques caractéristiques de $T$:</p>

```{r résumé-sommaire, fig.width = 7, out.width = "70%"}
sommaire <- summary(df.countries$Téléphones)
mu = sommaire["Mean"]
sommaire
boxplot_téléphones <- ggplot(data=df.countries) + aes(y=Téléphones) + geom_boxplot() + labs(title = "Box-plot de T") + theme(plot.title = element_text(hjust = 0.5))
boxplot_téléphones
```


<p style="text-indent: 20px"> Par lecture de notre sommaire et de notre box-plot, on obtient que la loi n'est pas symétrique, puisque la moyenne, `r mu` est différente de la médiane,`r sommaire["Median"]`.</p>

<p style="text-indent: 20px">Les deux indicateurs de tendance centrales sont assez bas. Le premier quartile est à `r sommaire["1st Qu."]` mais surtout le troisième quartile est égal à `r sommaire["3rd Qu."]`. Cela signifie que 75% des pays ont moins de `r sommaire["3rd Qu."]` téléphones pour mille habitants.</p>

<p style="text-indent: 20px">L'étendue est de `r sommaire["Max."] - sommaire["Min."]`. Cet indicateur est sensible aux valeurs aberrantes et nous voyons dans notre box-plot que nous en avons une. De plus, la longueur d'une des moustaches est assez élevée. L'écart-interquartile est de `r sommaire["3rd Qu."] - sommaire["1st Qu."]`. Ainsi, la moitié des pays ont entre `r sommaire["1st Qu."]` et `r sommaire["3rd Qu."]` téléphones pour mille habitants.</p>

``` {r}
a<-which.max(df.countries$Téléphones)
b<-df.countries[a,]
```
 
 
<p style="text-indent: 20px">L'observation hors-norme est due aux `r b$Pays` soit les États-Unis. Ce n'est pas suprenant que ce soit le pays qui ait le plus de téléphones pour mille habitants, au vue de leur histoire avec les technologies. Nous voyons sur le box-plot qu'il n'est pas tant éloigné de la fin de la moustache. </p>

<br><br> <p style="text-indent: 20px">Avant toutes recherches plus précises sur notre variable $T$, nous allons nous convaincre qu'elle est continue. Pour ce faire, traçons sa fonction de répartition empirique.</p>

```{r fdrplot, fig.width = 6, out.width = "70%"}
fdrplot <- ggplot(df.countries, aes(Téléphones)) + stat_ecdf(geom="step") + labs(title="Fonction de répartition empirique de T" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))
long <- length(unique(df.countries$Téléphones))
fdrplot
```


<br><br> <p style="text-indent: 20px">La fonction de répartition empirique de $T$ réalise `r long` sauts, ce qui est  suffisamment "grand" devant `r dim(df.countries)[1]` donc notre variable d’intérêt est continue.</p>

Nous pouvons alors tracer son histogramme. 
```{r histogrammes-T, fig.width = 7, out.width = "100%"}

hist <- ggplot(df.countries, aes(Téléphones)) + geom_histogram(bins = 10)
hist <- hist + labs(title="Histogramme de T", subtitles=" 10 sous-intervalles de [0,1000]" ) + xlab("Nombres de téléphones pour mille habitants") + ylab("") + theme(plot.title = element_text(hjust = 0.5))

hist
```


<br><br><p style="text-indent: 20px">L'histogramme est uni-modal avec un pic en 0, puis à tendance décroissante. On en déduit que dans notre jeu de données, beaucoup de pays ont moins de 100 téléphones pour mille habitants et à l'inverse, peu de pays ont plus de de 700 téléphones pour mille habitants.</p>

<br><p style="text-indent: 20px">Au vu de cet histogramme, nous pouvons penser que $T$ est un échantillon de loi exponentielle, c'est-à-dire que $T$ est la réalisation d'une variable aléatoire  $X$ suivant une loi exponentielle de paramètre $\lambda$. L'espérance d'une loi exponentielle est $\frac{1}{\lambda}$. La méthode des moments nous propose la moyenne empirique de $T$ comme estimateur sans biais, consistant et asymptotiquement normal de l'espérance. </p>

<p style="text-indent: 20px">La moyenne empirique de $T$ est $\mu =$ `r mu`. En prenant $\hat \lambda =$ `r 1/mu`, nous voulons vérifier que notre hypothèse est acceptable. Nous allons alors tracer le QQ-plot entre les quantiles théoriques de $X$  et les quantiles empiriques de $T$. </p>


```{r T-exponentielle, fig.height = 6, fig.width = 8, out.width = "100%"}

df.qq <- data.frame(df.countries$Téléphones)
names(df.qq) <- "Téléphones"
df.qq$Téléphones <- df.qq$Téléphones/mu
qqplot <- ggplot(data = df.qq, aes(sample = Téléphones)) + stat_qq(distribution = stats::qexp)
qqplot <- qqplot + geom_abline(intercept = 0,slope = 1, col = "blue") + labs(title="Diagramme quantile-quantile") + xlab("Quantiles théoriques") + ylab("Quantiles obeservés") + theme(plot.title = element_text(hjust = 0.5))
qqplot

```

<br><br><p style="text-indent: 20px">Les points de notre QQ-plot s'alignent bien sur la première bissectrice. C'est encourageant. L'adéquation n'est pas parfaite mais elle est suffisamment raisonnable pour retenir l'hypothèse que $T$ suit une loi exponentielle de paramètre $\hat \lambda$. </p>

<p style="text-indent: 20px">Nous allons finaliser notre analyse univariée en réalisant un test de Kolmogorov-Smirnov sur notre échantillon, puisque la variable Téléphones et la loi exponentielle sont toutes deux de lois continues. </p>
   
```{r test-T}
rexpsample <- df.countries$Téléphones/mu
kstest <- ks.test(df.countries$Téléphones, rexpsample)
kstest
p <- kstest$p.value
```

<br><p style="text-indent: 20px">Notre p-valeur est inférieure à 2.2e-16 donc on rejette $H_0$ au profit de l'hypothèse alternative $H_1$ sans hésitation. On peut conclure que notre variable $T$ ne suit pas une loi exponentielle de paramètre $\hat\lambda$. $T$ est la réalisation d'une autre loi, dont on ne connait pas la nature exacte.</p> 

<br><p style="text-indent: 20px">Nous avons ainsi terminé cette partie d'analyse univariée. </p>


#### <br> C - Analyse bi-variée  


<br><p style="text-indent: 20px">Nous allons maintenant nous intéresser aux potentielles corrélations entre notre variable d’intérêt $T$ et les autres variables de notre jeu de données.</p> 

<p style="text-indent: 20px">Commençons par calculer la matrice de corrélation et présentons un diagramme de dispersion de toutes les paires de variables, pour chaque variable quantitative de notre jeu de données. </p>

```{r corrélations-df, results = 'hide', fig.width = 7, out.width = "100%"}

df.countries.sans.pays <- df.countries[, -c(1)]
df.countries.sans.pays.region <- df.countries.sans.pays[, -c(2)]
df.countries.sans.pays.region <- scale(df.countries.sans.pays.region)
df.countries.sans.pays.region <- as.data.frame(df.countries.sans.pays.region)
ggpairs1 <- ggpairs(df.countries.sans.pays.region[, c(1:3,6)])
ggpairs2 <- ggpairs(df.countries.sans.pays.region[, c(1,4:5)])

cor(df.countries.sans.pays.region)
ggpairs1
ggpairs2
```


<p style="text-indent: 20px">On a un facteur de corrélation d'environ 0.85 pour le couple de variables $T$ et PIB; on en déduit qu'elles sont fortement corrélées linéairement. Il en est de même pour les variables Services et $T$ avec un facteur de corrélation de 0.68.
Finalement, la variable $T$ est également corrélée négativement à la variable Agriculture avec un coefficient de corrélation de -0,62 et à la variable Taux de natalité avec un coefficient de -0,73. </p>

<p style="text-indent: 20px">Analysons maintenant les nuages du points des paires de variables:</p>

* ($T$, Densité de population): la tendance semble montrer une corrélation, mais c'est peut être l'effet de certaines observations très grandes, qui ont écrasé un nuage de points qui aurait semblé aléatoire. Le coefficient est en lui même faible.

* ($T$, PIB): les points sont relativement alignés sur une droite, ce qui est cohérent avec le coefficient de corrélation.

* ($T$, Taux de natalité): les points ont l'air concentré dans une région du plan sous une hyperbole et dans le premier quart du plan. Le modèle idéal n'est peut être pas linéaire pour cette variable.

* ($T$, Agriculture): même remarque que pour le taux de natalité.

* ($T$, Services): ici la tendance est marquée sur le nuage, avec le plus grand des coefficients de corrélation.


<p style="text-indent: 20px">Nous avons maintenant une idée plus claire des liens entre notre variables d’intérêt et les variables quantitatives de notre jeu de données. </p>

<br><p style="text-indent: 20px">Nous allons terminer cette partie en nous intéressant à la variables Région, qui est une variable qualitative. Traçons le boxplot de la variable $T$ pour chaque modalité de la variable Région. </p>

```{r boxplot-régions, fig.width = 7, out.width = "100%"}
boxplot_region <- ggplot(data=df.countries) + aes(x=as.factor(Région), y=Téléphones) + scale_x_discrete(guide = guide_axis(n.dodge=4)) + geom_boxplot() +xlab("Régions") + labs(title="Boxplot de T en fonction de la variable Région") + theme(plot.title = element_text(hjust = 0.5))
boxplot_region
```


<p style="text-indent: 20px">Les boxplots sont très différents, on peut penser que la région d’appartenance du pays joue un rôle important sur la variables $T$. On remarque qu'en Amérique du nord et en Europe de l'ouest, les médianes régionales sont hautes et qu'elles sont beaucoup plus basses en Afrique Sub-saharienne, en Océanie ou encore en Asie. Il y a parfois des observations hors-normes, notamment en Afrique sub-saharienne. Nous reviendrons, ci-besoin, sur ces observations plus loin dans notre rapport.</p>


### <br> <br> II - Régression linéaire multiple

#### <br> A - Modèle général

<br><p style="text-indent: 20px">Dans cette partie, nous allons nous intéresser à une régression linéaire permettant d'exprimer la vraible $T$ par la densité de population (nombre d'habitants par miles carré), le PIB par habitant, le taux de natalité et enfin la part de la population active travaillant dans l'agriculture et les services.</p>


<p style="text-indent: 20px">On considère le modèle linéaire suivant:</p>

<p style="text-align: center;">
Téléphones = $\beta_0$ + $\beta_1$Densité + $\beta_2$PIB + $\beta_3$ Agriculture + $\beta_4$Services +  $\beta_5$Taux de natalité + $\varepsilon$
</p>

<p style="text-indent: 20px"> Nous avons déjà une première idée des corrélations linéaires de nos variables grace à la partie Analyse bi-variée. Nous allons ici formaliser ces relations et trouver les coefficients $\beta_j$. Dans le but de pouvoir comparer les $\beta_j$, nous devons centrer-réduire nos données et réaliser une régression sur ce nouveau jeu de données.

<p style="text-indent: 20px">Réalisons une première régression linéaire. </p>

```{r sommaire-régression, fig.width = 7, out.width = "100%"}
df.countries.scale<-df.countries
df.countries.scale[,c(2,4:8)] <- scale(df.countries[,c(2,4:8)])
df.countries.scale <- as.data.frame(df.countries.scale)

mod1 <- lm(Téléphones ~  Densité.population + PIB + Agriculture + Services + Taux.de.natalité, data = df.countries.scale)
summary(mod1)
```

<p style="text-indent: 20px">Annalysons ce sommaire. Le $R^2$ vaut 0,8192 qui est proche de 1 avec une p-valeur associée très faible,donc on rejette l'hypothèse selon laquelle tous les $\beta_j$ sont nuls pour $j=0,...,5$. Le modèle de régression linéaire permet d'expliquer relativement bien notre variable $T$. </p>

<p style="text-indent: 20px"> De plus, les tests de significativité des coefficients  $\beta_2$, $\beta_4$ et $\beta_5$ donnent des p-valeurs inférieures à 0.001, donc $\beta_2$, $\beta_4$ et $\beta_5$ sont non nuls. </p>
 
 
<p style="text-indent: 20px"> Nous allons vérifier que nos variables sont de "bonnes qualités" en cherchant si nous avons des valeurs aberrantes, des points leviers ou des distance de Cook trop élevées. Commençons par les valeurs aberrantes et les points levier.  </p>


```{r résidus-student-levier, fig.width = 7, out.width = "70%"}
df.residus <- data.frame(residu = rstudent(mod1))
n <- length(df.countries.scale$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
# n-p-1=203 >30 donc OK de prendre 2
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupes <- rep("Valeur non aberrante", n)
df.residus[ID_suspect, ]$Groupes <- "Valeur aberrante"

plot_rstudent <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupes) + geom_point()
plot_rstudent <- plot_rstudent + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent <- plot_rstudent + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes") + theme(plot.title = element_text(hjust = 0.5))

b<-sum(abs(df.residus$residu) > 2)

# Points leviers
p <- mod1$rank
# p vaut6 donc on regarde surtout le seuil de Hoaglin & Welsch soit le seuil 1
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod1))
ID_levier <- (1:n)[df.H$H>seuil1]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupes <- rep("Point non levier", n)
df.H[ID_levier, ]$Groupes <- "Point levier"

plot_levier <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupes) + geom_point()
plot_levier <- plot_levier + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier <- plot_levier + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier <- plot_levier + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier <- plot_levier + xlab('Index') + ylab('hii') + labs(title="Analyse des points levier") + theme(plot.title = element_text(hjust = 0.5))


a<-sum(df.H$H>seuil1)

grid.arrange(plot_levier , plot_rstudent, layout_matrix = rbind(c(2,1),c(2,1)), widths = c(1/2, 1/2))
```
<p style="text-indent: 20px">On a `r b` valeurs aberrantes dans un échantillon de taille `r dim(df.countries.scale)[1]` donc 95% des résidus studentisés $t_i^*$ se trouvent dans l'intervalle [−2,2], soit une proportion acceptable. De plus, il y a `r a` points leviers qui dépassent le deuxième seuil. Parmi les points leviers, l'observation 115, qui est le Luxembourg, est également une observation abérrante. Vérifions à présent les distances de Cook. <p>

```{r dist.cook, fig.width = 7, out.width = "70%"}
df.cook <- data.frame(cook = cooks.distance(mod1))
s1 <- qf(0.1, p, n-p)
s2 <- qf(0.5, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 3)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 2)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analyse des distances de Cook") + theme(plot.title = element_text(hjust = 0.5))
plot_cook

l<- which.max(cooks.distance(mod1))
```
<br><p style="text-indent: 20px">Aucune valeur n'a une distance de Cook supérieure au deuxième seuil, donc nous pouvons garder toutes nos observations.</p>


<br><p style="text-indent: 20px">Nos observations sont de "bonnes qualités". Nous pouvons donc réaliser une sélection de variables. </p>

#### <br> B - Sélection de variables

<br><p style="text-indent: 20px"> Toutes nos variables sont potentiellement explicatives, trouvons celles qui interviennent réellement dans l'explication de $T$. </p>

<p style="text-indent: 20px">Commençons par regarder les facteurs d'inflation de la variance (VIF), pour vérifier si nos variables explicatives ne sont pas trop corrélées entre elles. </p>

```{r vif}
vif(mod1)
```
Tout nos VIFS sont acceptables (inférieurs à 3).  
 
<p style="text-indent: 20px">Pour faire notre selection parmi les variables restantes,nous allons utiliser une procédure de modèle emboité. Comme notre modèle contient la constante, nous pouvons nous intéresser à la maximisation de $R^2_a$ et au critère BIC (Bayesian Information Criterion). </p>
 
<p style="text-indent: 20px">Commençons par un modèle avec nos 5 variables explicatives.</p>
 
```{r choix-modèle1, fig.width = 10, out.width = "80%"}
choix <- regsubsets(Téléphones~ Densité.population + PIB + Agriculture  + Taux.de.natalité , data = df.countries.scale, nvmax = 5, really.big = T)
par(mfrow = c(1, 2))
plot(choix, scale="bic")
plot(choix, scale="adjr2")
```
<p style="text-indent: 20px">Nous supprimons les variables Densité et Agriculture. </p>
 
```{r choix-modèle2}
mod3<-lm(Téléphones ~ PIB + Services + Taux.de.natalité, data = df.countries.scale)
```

<p style="text-indent: 20px">On itère le procédé avec nos 3 variables explicatives restantes. </p>
 
```{r choix-modèle3, out.height="100%", fig.width = 10, out.width = "80%"}
choix<-regsubsets(Téléphones~ PIB + Services + Taux.de.natalité , data = df.countries.scale, nvmax=3, really.big=T)
par(mfrow = c(1, 2))
plot(choix, scale="bic")
plot(choix, scale="adjr2")
```
<p style="text-indent: 20px">Nous gardons l'ensemble des variables restantes, c'est à dire le PIB, les Services et le Taux de natalité.  </p>
 
```{r}
summary(mod3)
```

 
<p style="text-indent: 20px">Finalement, après l'étape de sélection, notre modèle linéaire s'écrit:</p>

<h4 style="text-align: center;">
Téléphones = 0,58 PIB + 0,24 Agriculture -0,22 Taux de natalité + $\varepsilon$
</h4>

Avec $\varepsilon$ une variable aléatoire inconnues. 

#### <br> C - Validation du modèle

<br><p style="text-indent: 20px"> Nous allons vérifier à nouveau que nous n'avons pas de valeurs problématiques en regardant les valeurs aberrantes, les points leviers et les distance de Cook.    </p>

```{r residus-student3, fig.width = 7, out.width = "100%"}
df.residus <- data.frame(residu = rstudent(mod3))
n <- length(df.countries.scale$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
# n-p-1=203 >30 donc OK de prendre 2
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupes <- rep("Valeur non aberrante", n)
df.residus[ID_suspect, ]$Groupes <- "Valeur aberrante"

plot_rstudent <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupes) + geom_point()
plot_rstudent <- plot_rstudent + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent <- plot_rstudent + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent <- plot_rstudent + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des valeurs aberrantes") + theme(plot.title = element_text(hjust = 0.5))

b<-sum(abs(df.residus$residu) > 2)

# Points leviers
p <- mod3$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod3))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupes <- rep("Point non levier", n)
df.H[ID_levier, ]$Groupes <- "Point levier"

plot_levier <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupes) + geom_point()
plot_levier <- plot_levier + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier <- plot_levier + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier <- plot_levier + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier <- plot_levier + xlab('Index') + ylab('hii') + labs(title="Analyse des points levier") + theme(plot.title = element_text(hjust = 0.5))


a<-sum(df.H$H>seuil2)

df.cook <- data.frame(cook = cooks.distance(mod3))
s1 <- qf(0.1, p, n-p)
s2 <- qf(0.5, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 3)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 2)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analyse des distances de Cook") + theme(plot.title = element_text(hjust = 0.5))


l<- which.max(cooks.distance(mod3))

grid.arrange(plot_rstudent, plot_levier, layout_matrix = rbind(c(1,2)), widths = c(1/2, 1/2))
plot_cook
```

<p style="text-indent: 20px">On a `r b` valeurs aberrantes dans un échantillon de taille `r dim(df.countries.scale)[1]` donc 95% des résidus studientisés $t_i^*$ se trouvent dans l'intervalle [−2,2]. Il y a `r a` points leviers qui dépassent le deuxième seuil. Parmi les points leviers, l'observation 115, qui est le Luxembourg, est également une observation abérrante. Nous avons une valeur qui a une distance de Cook qui dépasse le seuil préocuppant (`r s2`) qui est également le `r l`. Nous décidons donc de supprimer cette observation et de réaliser une nouvelle régression linéaire. </p>


```{r}
nouvcountries <- df.countries.scale[c(-115), ]
mod4 <- lm(Téléphones ~  PIB + Services + Taux.de.natalité, data = nouvcountries)
summary(mod4)
```

<br><p style="text-indent: 20px"> Ainsi, après la sélection de variable et l'étude des observations, on en déduit que notre notre modèle linéaire s'écrit:</p>

<h4 style="text-align: center;">
Téléphones = 0,65 PIB + 0,24 Services -0,18 Taux de natalité + $\varepsilon$
</h4>

Nous avons centré et réduit nos observations donc nos coefficients $\beta_j$ sont comparables. dans un modèle linéaire, c'est le PIB du pays qui influence le plus $T$. la part de la population dans les serives inflence également positivement $T$, même si cette infleunce est moindre. Finalement, le taux de natalité du pays infleunce également $T$ mais cette fois-ci négativement. 

Notons que les coefficients diffèrent des coefficients précemment trouvés lorqu'on avait gardé le Luxembourg. 

<br><p style="text-indent: 20px">À présent, nous allons réaliser une analyse de la normalité des résidus, pour vérifier si notre modèle linéaire est bien Gaussien.  Traçons un QQ-plot qui compare les quantiles empiriques associés aux studendisés ($t_1^*,...,t_n^*$) aux quantiles de la loi de Student $\mathcal{T}(n-p-1)$ pour valider l'hypothèse que les résidus sont suivent une loi normale. </p>


```{r qqplot-residus, fig.width = 7, out.width = "70%"}
# QQ-plot residus et studentisés

n <- length(nouvcountries$Téléphones)
p <- mod4$rank
df.residus2 <- data.frame(residu = rstudent(mod4))

quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs = sort(df.residus2$residu), Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)") + labs(title="QQ-plot quantiles des studentisés contre quantiles théoriques") + theme(plot.title = element_text(hjust = 0.5))
qq.plot
```


<br><p style="text-indent: 20px"> Le QQ-plot des résidus studendisées contre les quantiles d'une loi de Student de degrés de liberté n-p-1 =`r n-p-1` semble raisonnable. 
Nous pouvons donc valider l'hypothèse de la normalité des résidus. Notre modèle linéaire est donc Gaussien. </p>


## III - Modélisation linéaire avec variable qualitative, réalisation d'une ANOVA. 

### A- Apprentissage du modèle 

<br><p style="text-indent: 20px"> La parti précedente nous a conforté dans l'idée qu'un modèle linéaire  explique relativement bien $T$. Nous souhaitons donc ajouter une nouvelle variable, cette fois-ci qualitative, potentiellement explicative de $T$:la Région d'appartenance du pays.Nous gardons donc nos trois variables quantitatives précédentes (pour se limiter à une étude de taille acceptable) soit le PIB, le taux de natalité et la proportion de la population dans les services et nous ajoutons la variable région.</p>

<p style="text-indent: 20px"> Nous avons observé dans la partie analyse bi-variée que la région d'appartenance du pays influe sur $T$ (voir QQ-plot par région). Nous voudrions donc savoir à quel point cette influence est forte, et s'il existe des effet d'intération entre nos quatre variables explicatives.</p>


<p style="text-indent: 20px"> Nous allons réaliser une ANOVA que un jeu de donné d'apprentissage comprenant 80% de nos pays étudiés, puis vérifier à l'aide des 20% de pays restants la précision de notre modèle trouvé. </p>


```{r}
idx = sample(1:208, 166)
df.countries.scale.app<- df.countries.scale[idx,]
df.countries.scale.test<-df.countries.scale[-idx,]


complet <- lm(Téléphones~ Région * Services * Taux.de.natalité * PIB, data= df.countries.scale.app)
summary(complet)
```
Pour le modèle complet, le $R^2$ est égal à 0,9251 et la p-valeur du test global de Fisher indiquent que le modèle explique moieux la réalité que le modèle contenant uniquement la constante. 

Nous allons maintenant réaliser une sélection de variables. 

```{r}
anova(complet)
```

De nombreuses interactions entre nos variables ne semblent pas avoir d'effet significatif sur $T$, nous les supprimont. 
 
```{r}
mod.sans.int <-  lm(Téléphones~ Région + Services + Taux.de.natalité + PIB + PIB:Région + Services:Taux.de.natalité + Services:Région + Taux.de.natalité:PIB + Région:Taux.de.natalité , data= df.countries.scale.app)
anova(mod.sans.int)
```

Idem, nous enlevons les 3 interactions non significatives. 
```{r}
mod.sans.int2 <-  lm(Téléphones~ Région + Services + Taux.de.natalité + PIB + PIB:Région + Services:Taux.de.natalité, data= df.countries.scale.app)
anova(mod.sans.int2)
```

Toutes les variables et interactions restantes sont significatives. La probabilité critique associée à la variable région est inférieure à 0.1%. On rejette donc l'hypothèse que la région d'appartenance du pays n'a pas d'effet sur $T$. On retient que les variables PIB, Services et Taux de natalité ont encore un effet sur $T$. De plus, nous apprenons ici qu'il y a un effet d'interaction entre la Région et le PIB  ainsi  qu'entre Services et Taux de natalité. 

Finissons par réaliser une analyse des résidus. 

Commençons par regarder si nous avons des valeurs aberrantes et des points leviers. 

```{r residus-student, fig.width = 9, out.width = "100%"}
df.residus <- data.frame(residu = rstudent(mod.sans.int2))
n <- length(df.countries.scale.app$Téléphones)

ID_suspect <- (1:n)[abs(df.residus$residu) > 2]
df.residus$ID <- rep("", n)
df.residus[ID_suspect,]$ID <- ID_suspect
df.residus$Groupe <- rep("Non aberrante", n)
df.residus[ID_suspect, ]$Groupe <- "Aberrante"

plot_rstudent2 <- ggplot(data = df.residus) + aes(x = 1:n, y = residu, color=Groupe) + geom_point()
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = -2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_hline(yintercept = 2, col = "blue", linetype = 2)
plot_rstudent2 <- plot_rstudent2 + geom_text(aes(label=ID),hjust = 0, vjust = 0)
plot_rstudent2 <- plot_rstudent2 + xlab('Index') + ylab('Résidus studentisés') + labs(title="Analyse des Valeurs aberrante, ANOVA") + theme(plot.title = element_text(hjust = 0.5))


t<-sum(abs(df.residus$residu) > 2)

p <- mod.sans.int2$rank
seuil1 <- 2*p/n
seuil2 <- 3*p/n
df.H <- data.frame(H = hatvalues(mod.sans.int2))
ID_levier <- (1:n)[df.H$H>seuil2]
df.H$ID <- rep("", n)
df.H[ID_levier, ]$ID <- ID_levier
df.H$Groupe <- rep("Non levier", n)
df.H[ID_levier, ]$Groupe <- "Levier"

plot_levier2 <- ggplot(data = df.H) + aes(x=1:n, y = H, color = Groupe) + geom_point()
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil1, col = "blue", linetype = 2)
plot_levier2 <- plot_levier2 + geom_hline(yintercept = seuil2, col = "blue", linetype = 3)
plot_levier2 <- plot_levier2 + geom_text(aes(label=ID), hjust=0, vjust=0)
plot_levier2 <- plot_levier2 + xlab('Index') + ylab('hii') + labs(title="Analayse des points levier, ANOVA") + theme(plot.title = element_text(hjust = 0.5))


grid.arrange(plot_rstudent2, plot_levier2, layout_matrix = rbind(c(1,2),c(1,2)), widths = c(1/2, 1/2))

u<- sum(abs(hatvalues(mod.sans.int2) > seuil2))
```
Nous avons `r t`valeurs aberrantes, soit `(t/n)*100` % de nos observations sont dans l'intervalle [-2;2] ce qui est acceptable (suffisamment proche de 0.5%). Nous avons `r u` points leviers. Aucune observation n'est à la fois levier et aberrante. Analysons à présent les distances de Cook. 

 
```{r df-cook-anov, fig.width = 10, out.width = "100%"}
df.cook <- data.frame(cook = cooks.distance(mod.sans.int2))
s1 <- qf(0.5, p, n-p)
s2 <- qf(0.1, p, n-p)
plot_cook <- ggplot(data = df.cook) + aes(x=1:n, y = cook) + geom_point()
plot_cook <- plot_cook + geom_hline(yintercept = s1, col = "blue", linetype = 2)
plot_cook <- plot_cook + geom_hline(yintercept = s2, col = "blue", linetype = 3)
plot_cook <- plot_cook + xlab('Index') + ylab('Distance de Cook') + labs(title="Analayse des distances de Cook, ANOVA") + theme(plot.title = element_text(hjust = 0.5))
plot_cook
```

Aucune distance de Cook ne dépasse le premier seuil et à fortiori le deuxième. Nous pouvons donc garder toutes nos observations. 
 
 Finalisons cette analyse en vérifiant l'hypothèse de normalité des résidus. 
 
```{r}
quant.t <- qt((1:n)/n, n-p-1)

df_qq <- data.frame(Obs = sort(df.residus$residu), Theo = quant.t)
qq.plot <- ggplot(data = df_qq, aes(x = Obs, y = Theo)) + geom_point(shape = 3, size = 2.5)
qq.plot <-
  qq.plot + geom_abline(
    slope = 1,
    intercept = 0,
    col = "blue",
    linetype = 2,
    size = 0.5
  )
qq.plot <- qq.plot + xlab("Quantiles empiriques des résidus") + ylab("Quantiles d'une loi de Student T(n-p-1)") + labs(title="QQ-plot quantiles des studentisés contre quantiles théoriques, ANOVA") + theme(plot.title = element_text(hjust = 0.5))
qq.plot
```
 On peut valider l'hypothèse selon laquelle les résidus sont gaussiens. 
 Pour conclure, on accepte notre modèlisation du problème